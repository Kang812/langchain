{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello LangChain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_g\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 정형외과 전문의 입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt + llm + output \n",
    "\n",
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ \n",
    "     #(\"system\", \"당신은 개발자입니다.\")\n",
    "     (\"system\", \"당신은 정형외과 전문의 입니다.\") , \n",
    "     (\"user\", \"{input}\") ]\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt_text = prompt.format(input=\"파이썬은 무엇인가요? 자세하게 설명해주세요\")\n",
    "#prompt_text = prompt.format(input=\"OA Progression이 48개월 이내에 진행이 될 수 있고, 정상대비 JSW의 감소율이 25% KL Grade 3 이고, 골극의 개수가 3개일 때, 종합적인 진단을 진행해줘\")\n",
    "input = \"\"\"\n",
    "OA Progression이 48개월 이내에 진행이 될 수 있고, 정상대비 JSW의 감소율이 25% KL Grade 3 이고, 골극의 개수가 3개일 떄 아래의 Format으로 초기 진단서를 작성해줘, \n",
    "**초기 진단서**\n",
    "\n",
    "환자 정보:\n",
    "- 이름: \n",
    "- 나이: \n",
    "- 성별: \n",
    "\n",
    "관찰된 증상 및 징후:\n",
    "- JSW(Joint Space Width) 감소율: \n",
    "- KL(Kellgren-Lawrence) 등급: \n",
    "- 골극(osteophyte) 개수: \n",
    "\n",
    "48개월 이내에 OA 진행 여부:\n",
    "\n",
    "임상적 판단:\n",
    "\n",
    "진단:\n",
    "\n",
    "치료 계획:\n",
    "\n",
    "\"\"\"\n",
    "prompt_text = prompt.format(input=input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000022B564E1430>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000022B564FBC80>, root_client=<openai.OpenAI object at 0x0000022B564E16A0>, root_async_client=<openai.AsyncOpenAI object at 0x0000022B564FC410>, model_name='meta-llama/llama-4-scout-17b-16e-instruct', temperature=0.4, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#llm = ChatOpenAI(api_key=OPENAI_API_KEY, model_name=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# Groq API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    #temperature=0.7\n",
    "    temperature=0.4)\n",
    "\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "응답: **초기 진단서**\n",
      "\n",
      "환자 정보:\n",
      "- 이름: [환자 이름]\n",
      "- 나이: [환자 나이]\n",
      "- 성별: [환자 성별]\n",
      "\n",
      "관찰된 증상 및 징후:\n",
      "- JSW(Joint Space Width) 감소율: 정상 대비 25% 감소\n",
      "- KL(Kellgren-Lawrence) 등급: 3 등급\n",
      "- 골극(osteophyte) 개수: 3 개\n",
      "\n",
      "48개월 이내에 OA 진행 여부: 예, 48개월 이내에 진행될 수 있음\n",
      "\n",
      "임상적 판단: 환자의 증상 및 징후를 바탕으로 골관절염(Osteoarthritis, OA)이 의심되며, 향후 48개월 이내에 질환 진행 가능성이 있음.\n",
      "\n",
      "진단: 골관절염(Osteoarthritis, OA) 의심\n",
      "\n",
      "치료 계획: \n",
      "- 정기적인 관찰 및 추적 검사를 통해 질환 진행을 모니터링 함.\n",
      "- 환자의 증상 완화를 위해 약물 치료(예: 통증 완화제) 고려.\n",
      "- 물리 치료 및 재활 프로그램을 통해 관절 기능 유지 및 강화.\n",
      "- 생활 습관 변화(예: 체중 관리, 적절한 운동)를 권장.\n",
      "\n",
      "※ 위의 내용은 일반적인 치료 계획이며, 실제 치료는 환자의 구체적인 상태와 의사의 전문적 판단에 따라 달라질 수 있음.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(type(response))\n",
    "    print(\"응답:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "# Runnable\n",
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"input\":\"지구의 자전주기는 얼마인가요?\"})\n",
    "print(type(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "지구의 자전주기는 24시간입니다.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-app-qc8Qb1Xk-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
