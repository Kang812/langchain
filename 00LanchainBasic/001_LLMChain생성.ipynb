{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a",
   "metadata": {
    "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a"
   },
   "source": [
    "### LLM Chain ë§Œë“¤ê¸°\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9",
   "metadata": {
    "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9"
   },
   "source": [
    "## 1. í™˜ê²½ êµ¬ì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81",
   "metadata": {
    "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81"
   },
   "source": [
    "### 1) ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
    "outputId": "c96ed02d-19b7-4e90-d92e-1ae52895e303"
   },
   "outputs": [],
   "source": [
    "#%pip install -q langchain langchain-openai dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55152049-e9e5-4952-8e19-409f58cf3ac9",
   "metadata": {
    "id": "55152049-e9e5-4952-8e19-409f58cf3ac9"
   },
   "source": [
    "### 2) OpenAI ì¸ì¦í‚¤ ì„¤ì •\n",
    "https://openai.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b76f68a8-4745-4377-8057-6090b87377d1",
   "metadata": {
    "id": "b76f68a8-4745-4377-8057-6090b87377d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ì„œ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e09aaca6-5aa2-4b52-bbfc-196e808dc5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.26\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c",
   "metadata": {
    "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c"
   },
   "source": [
    "## 2. LLM Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23729d10-9600-415b-b7d1-f954665224e3",
   "metadata": {
    "id": "23729d10-9600-415b-b7d1-f954665224e3"
   },
   "source": [
    "### 1) Prompt + LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "on0y4xF8VoyE",
   "metadata": {
    "id": "on0y4xF8VoyE"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# chain ì‹¤í–‰\n",
    "result = llm.invoke(\"ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ì— ëŒ€í•˜ì—¬ ì‰½ê²Œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.\")\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc4accf-c927-40a3-ba2c-f891c94c34f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WzcZy4PruV1n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "WzcZy4PruV1n",
    "outputId": "18ecc8f9-5748-4b16-cb07-4a0f7a01fb5a"
   },
   "outputs": [],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c97fc",
   "metadata": {},
   "source": [
    "### 2) PromptTemplate + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SeNi_VXqYD-b",
   "metadata": {
    "id": "SeNi_VXqYD-b"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}ì— ëŒ€í•´ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01WLucSpYjZt",
   "metadata": {
    "id": "01WLucSpYjZt"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# chain ì—°ê²° (LCEL)\n",
    "chain = prompt | llm\n",
    "print(type(chain))\n",
    "\n",
    "# chain í˜¸ì¶œ\n",
    "result = chain.invoke({\"input\": \"ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬\"})\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170ec878",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56848a4c",
   "metadata": {},
   "source": [
    "### 3) PromptTemplate + LLM(invoke()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1e9009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. ì»´í¬ë„ŒíŠ¸ ì •ì˜\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}ì— ëŒ€í•´ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AIì™€ ë™ì¼í•œ ëª¨ë¸\n",
    "    temperature=0.7)\n",
    "\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 2. chain ìƒì„± (LCEL)\n",
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "\n",
    "# 3. chainì˜ invoke í˜¸ì¶œ\n",
    "result = chain.invoke({\"input\": \"ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬\"})\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ca7cdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ëŠ” ì‚¬ëŒì˜ ë‡Œê°€ í•™ìŠµí•˜ëŠ” ì›ë¦¬ì™€ ìœ ì‚¬í•©ë‹ˆë‹¤. ì»´í“¨í„°ì—å¤§é‡çš„ ë°ì´í„°ë¥¼ ì œê³µí•˜ê³ , ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ íŒ¨í„´ì„ ì°¾ê³ , íŒ¨í„´ì„ ê¸°ë°˜ìœ¼ë¡œ ì˜ˆì¸¡ì´ë‚˜ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
      "\n",
      "êµ¬ì²´ì ìœ¼ë¡œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê³¼ì •ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.\n",
      "\n",
      "1. **ë°ì´í„° ìˆ˜ì§‘**: ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•´å¤§é‡çš„ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤. ì´ ë°ì´í„°ëŠ” ë¬¸ì œì— ë”°ë¼ ë‹¤ë¥´ì§€ë§Œ, ì´ë¯¸ì§€, í…ìŠ¤íŠ¸, ì˜¤ë””ì˜¤ ë“± ë‹¤ì–‘í•œ í˜•íƒœì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **ë°ì´í„° ì „ì²˜ë¦¬**: ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê¸° ì‰½ê²Œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ë°ì´í„°ë¥¼ ì •ì œí•˜ê³ , í•„ìš”í•œ ê²½ìš° ë°ì´í„°ë¥¼ ë³€í™˜í•˜ê±°ë‚˜ íŠ¹ì§•ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
      "\n",
      "3. **ëª¨ë¸ ì •ì˜**: ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì„ ì •ì˜í•©ë‹ˆë‹¤. ëª¨ë¸ì€ ë°ì´í„°ë¡œë¶€í„° íŒ¨í„´ì„ í•™ìŠµí•˜ê³ , ì˜ˆì¸¡ì´ë‚˜ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤. ì‹ ê²½ë§, ê²°ì • íŠ¸ë¦¬, ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹  ë“± ë‹¤ì–‘í•œ ëª¨ë¸ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "4. **í•™ìŠµ**: ëª¨ë¸ì— ë°ì´í„°ë¥¼ ì œê³µí•˜ê³ , ëª¨ë¸ì´ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ íŒ¨í„´ì„ í•™ìŠµí•˜ë„ë¡ í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œ ëª¨ë¸ì€ ë°ì´í„°ë¥¼ í†µí•´ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ë©°, ìµœì ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ìŠµë‹ˆë‹¤.\n",
      "\n",
      "5. **í‰ê°€**: í•™ìŠµëœ ëª¨ë¸ì„ í‰ê°€í•©ë‹ˆë‹¤. í‰ê°€ ë°ì´í„°ì— ëª¨ë¸ì„ ì ìš©í•˜ì—¬ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê³ , í•„ìš”ì— ë”°ë¼ ëª¨ë¸ì„ ì¡°ì •í•©ë‹ˆë‹¤.\n",
      "\n",
      "6. **ì˜ˆì¸¡ ë˜ëŠ” ë¶„ë¥˜**: í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ì´ë‚˜ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì˜ˆë¥¼ ë“¤ì–´, ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” ê²½ìš°ë¥¼ ìƒê°í•´ ë´…ì‹œë‹¤. ê³ ì–‘ì´ì™€ ê°•ì•„ì§€ì˜ ì´ë¯¸ì§€ë¥¼ ì»´í“¨í„°ì— ì œê³µí•˜ê³ , ì»´í“¨í„°ëŠ” ì´ë¯¸ì§€ì˜ íŠ¹ì§•ì„ ë¶„ì„í•˜ì—¬ ê³ ì–‘ì´ì™€ ê°•ì•„ì§€ë¥¼ êµ¬ë¶„í•˜ëŠ” ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤. ì´ ê³¼ì •ì„ í†µí•´ ì»´í“¨í„°ëŠ” ê³ ì–‘ì´ì™€ ê°•ì•„ì§€ì˜ íŒ¨í„´ì„ í•™ìŠµí•˜ê³ , ìƒˆë¡œìš´ ì´ë¯¸ì§€ê°€ ì£¼ì–´ì¡Œì„ ë•Œ ì´ë¥¼ ë¶„ë¥˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ¬í•œ í•™ìŠµ ì›ë¦¬ëŠ” ë‹¤ì–‘í•œ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì— ì ìš©ë˜ë©°, ì´ë¥¼ í†µí•´ ì»´í“¨í„°ëŠ” ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³ , ì˜ˆì¸¡ì´ë‚˜ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ëŠ” ëŠ¥ë ¥ì„ ê°–ê²Œ ë©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d997b16",
   "metadata": {},
   "source": [
    "### 4) PromptTemplate + LLM(stream()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684654e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ëŠ” ì‚¬ëŒì˜ ë‡Œê°€ í•™ìŠµí•˜ëŠ” ì›ë¦¬ì™€ ìœ ì‚¬í•©ë‹ˆë‹¤. \n",
      "\n",
      "1. **ë°ì´í„° ìˆ˜ì§‘**: ìš°ì„  ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•´ì„œëŠ” ìˆ˜ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤. \n",
      "\n",
      "2. **ë°ì´í„° ì…ë ¥**: ì´ ë°ì´í„°ë¥¼ ëª¨ë¸ì— ì…ë ¥í•©ë‹ˆë‹¤. \n",
      "\n",
      "3. **ì˜ˆì¸¡**: ëª¨ë¸ì€ ì…ë ¥ëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. \n",
      "\n",
      "4. **ì˜¤ì°¨ ê³„ì‚°**: ì˜ˆì¸¡ ê²°ê³¼ì™€ ì‹¤ì œ ê²°ê³¼ì˜ ì°¨ì´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ì´ë¥¼ 'ì˜¤ì°¨'ë¼ê³  í•©ë‹ˆë‹¤. \n",
      "\n",
      "5. **ëª¨ë¸ ì—…ë°ì´íŠ¸**: ì´ ì˜¤ì°¨ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëª¨ë¸ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤. ì¦‰, ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •í•˜ì—¬ ë‹¤ìŒ ì˜ˆì¸¡ì—ì„œëŠ” ë” ì •í™•í•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n",
      "\n",
      "6. **ë°˜ë³µ**: ì´ ê³¼ì •ì„ ë§¤ìš° ë§ì€ ë°ì´í„°ì— ëŒ€í•´ ë°˜ë³µ ìˆ˜í–‰í•©ë‹ˆë‹¤. \n",
      "\n",
      "ì´ë ‡ê²Œ ë°˜ë³µ í•™ìŠµì„ í†µí•´ ëª¨ë¸ì€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì˜ˆì¸¡í•˜ëŠ” ëŠ¥ë ¥ì„ í‚¤ìš°ê²Œ ë©ë‹ˆë‹¤. \n",
      "\n",
      "ì˜ˆë¥¼ ë“¤ì–´, ê³ ì–‘ì´ ì‚¬ì§„ìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ì—ê²Œ ìƒˆë¡œìš´ ê³ ì–‘ì´ ì‚¬ì§„ì„ ë³´ì—¬ì£¼ë©´, ëª¨ë¸ì€ ì´ì „ì— ë³´ì§€ ëª»í•œ ì‚¬ì§„ì´ì§€ë§Œ ê³ ì–‘ì´ë¼ëŠ” ê²ƒì„ ì¸ì‹í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "ì´ì²˜ëŸ¼ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì€ ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ í†µí•´ ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ê³ , ìƒˆë¡œìš´ ìƒí™©ì— ëŒ€ì²˜í•˜ëŠ” ëŠ¥ë ¥ì„ í‚¤ìš°ëŠ” ê²ƒì…ë‹ˆë‹¤."
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. ì»´í¬ë„ŒíŠ¸ ì •ì˜\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}ì— ëŒ€í•´ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AIì™€ ë™ì¼í•œ ëª¨ë¸\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "\n",
    "# chain ì—°ê²° (LCEL)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ì„ ìœ„í•œ ìš”ì²­\n",
    "answer = chain.stream({\"input\": \"ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬\"})\n",
    "# ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥\n",
    "#print(answer)\n",
    "\n",
    "for token in answer:\n",
    "    # ìŠ¤íŠ¸ë¦¼ì—ì„œ ë°›ì€ ë°ì´í„°ì˜ ë‚´ìš©ì„ ì¶œë ¥í•©ë‹ˆë‹¤. ì¤„ë°”ê¿ˆ ì—†ì´ ì´ì–´ì„œ ì¶œë ¥í•˜ê³ , ë²„í¼ë¥¼ ì¦‰ì‹œ ë¹„ì›ë‹ˆë‹¤.\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0188674-915f-41af-ac46-56f9f54289b0",
   "metadata": {
    "id": "b0188674-915f-41af-ac46-56f9f54289b0"
   },
   "source": [
    "##### 2) Multiple Chains\n",
    "* Multi Chainì„ í™œìš©í•œ ì˜í™” ì¶”ì²œ ë° ì¤„ê±°ë¦¬ ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
    "outputId": "7ee83878-5d1a-45e3-f033-100da33f3ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ì¶”ì²œëœ ì˜í™”: 'ë£¨ì¹´' (2021)ëŠ” ì´íƒˆë¦¬ì•„ ì• ë‹ˆë©”ì´ì…˜ ë“œë¼ë§ˆ ì˜í™”ì…ë‹ˆë‹¤. 11ì‚´ ì†Œë…„ ë£¨ì¹´ëŠ” ë°”ë‹¤ ê´´ë¬¼ë¡œ ì‚´ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŠ” ì¸ê°„ ì„¸ê³„ì— ëŒ€í•œ í˜¸ê¸°ì‹¬ì´ ë§ê³ , ì¹œêµ¬ë¥¼ ì‚¬ê·€ê³  ì‹¶ì–´ í•©ë‹ˆë‹¤. ë£¨ì¹´ëŠ” ì—¬ë¦„ì„ ë³´ë‚´ê¸° ìœ„í•´ ë°”ë‹¤ ê·¼ì²˜ì˜ ì‘ì€ ë§ˆì„ë¡œ ì´ë™í•©ë‹ˆë‹¤. ê·¸ê³³ì—ì„œ ê·¸ëŠ” ì•Œë² ë¥´í† ë¼ëŠ” ì†Œë…„ê³¼ ì¹œí•´ì§‘ë‹ˆë‹¤. ì•Œë² ë¥´í† ëŠ” ë£¨ì¹´ì™€ ê°™ì€ ë°”ë‹¤ ê´´ë¬¼ì…ë‹ˆë‹¤. ë‘ ì‚¬ëŒì€ ì¸ê°„ìœ¼ë¡œ ë³€ì¥í•˜ê³  ë§ˆì„ ì‚¬ëŒë“¤ê³¼ ì–´ìš¸ë¦½ë‹ˆë‹¤. í•˜ì§€ë§Œ ê·¸ë“¤ì˜ ë¹„ë°€ì€ ìœ„í—˜ì— ì²˜í•˜ê²Œ ë©ë‹ˆë‹¤.\n",
      "\n",
      "ì´ ì˜í™”ëŠ” ì•„ë¦„ë‹¤ìš´ ì• ë‹ˆë©”ì´ì…˜ê³¼ ê°ë™ì ì¸ ì´ì•¼ê¸°ë¡œ ë§ì€ ì‚¬ë‘ì„ ë°›ì•˜ìŠµë‹ˆë‹¤. ë°”ë‹¤ ê´´ë¬¼ì´ë¼ëŠ” ë…íŠ¹í•œ ì„¤ì •ê³¼ ì´íƒˆë¦¬ì•„ ë¬¸í™”ë¥¼ ë°°ê²½ìœ¼ë¡œ í•œ ì´ì•¼ê¸°ëŠ” ê´€ê°ë“¤ì—ê²Œ ìƒˆë¡œìš´ ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, ìš°ì •ê³¼ ì„±ì¥ì— ëŒ€í•œ ì´ì•¼ê¸°ëŠ” ëª¨ë“  ì—°ë ¹ëŒ€ì˜ ê´€ê°ì—ê²Œ ê°ë™ì„ ì¤„ ê²ƒì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¥ë¥´ì— ë”°ë¼ ì˜í™” ì¶”ì²œ\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} ì¥ë¥´ì—ì„œ ì¶”ì²œí•  ë§Œí•œ ì˜í™”ë¥¼ í•œ í¸ ì•Œë ¤ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# Step 2: ì¶”ì²œëœ ì˜í™”ì˜ ì¤„ê±°ë¦¬ë¥¼ ìš”ì•½\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} ì¶”ì „í•œ ì˜í™”ì˜ ì œëª©ì„ ë¨¼ì € ì•Œë ¤ì£¼ì‹œê³ , ì¤„ì„ ë°”ê¾¸ì–´ì„œ ì˜í™”ì˜ ì¤„ê±°ë¦¬ë¥¼ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì‚¬ìš©\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AIì™€ ë™ì¼í•œ ëª¨ë¸\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# ì²´ì¸ 1: ì˜í™” ì¶”ì²œ (ì…ë ¥: ì¥ë¥´ â†’ ì¶œë ¥: ì˜í™” ì œëª©)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# Step 1: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¥ë¥´ì— ë”°ë¼ ì˜í™” ì¶”ì²œ\n",
    "movie = chain1.invoke({\"genre\": \"Drama\"})  # ì˜í™” ì œëª© ì–»ê¸°\n",
    "print(\" ì¶”ì²œëœ ì˜í™”:\", movie)  # movie ê°’ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16718b76-f59d-48f7-906f-5d2371417803",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "16718b76-f59d-48f7-906f-5d2371417803",
    "outputId": "6e3371cd-d294-4be7-a868-2eae5ee6e5de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first={\n",
      "  movie: ChatPromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, template='{genre} ì¥ë¥´ì—ì„œ ì¶”ì²œí•  ë§Œí•œ ì˜í™”ë¥¼ í•œ í¸ ì•Œë ¤ì£¼ì„¸ìš”.'), additional_kwargs={})])\n",
      "         | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000211FE707590>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000211FE5E9310>, root_client=<openai.OpenAI object at 0x00000211F88BE480>, root_async_client=<openai.AsyncOpenAI object at 0x00000211FE7062A0>, model_name='meta-llama/llama-4-scout-17b-16e-instruct', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "         | StrOutputParser()\n",
      "} middle=[ChatPromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, template='{movie} ì¶”ì „í•œ ì˜í™”ì˜ ì œëª©ì„ ë¨¼ì € ì•Œë ¤ì£¼ì‹œê³ , ì¤„ì„ ë°”ê¾¸ì–´ì„œ ì˜í™”ì˜ ì¤„ê±°ë¦¬ë¥¼ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.'), additional_kwargs={})]), ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000211FE707590>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000211FE5E9310>, root_client=<openai.OpenAI object at 0x00000211F88BE480>, root_async_client=<openai.AsyncOpenAI object at 0x00000211FE7062A0>, model_name='meta-llama/llama-4-scout-17b-16e-instruct', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n",
      "\n",
      "ğŸ”¹ ì˜í™” ì¤„ê±°ë¦¬ ìš”ì•½:\n",
      " \"ë‚˜ëŠ” ë‹¤ë‹ˆì—˜ ë¸”ë ˆì´í¬\"ëŠ” ì¼„ ë¡œì¹˜ ê°ë…ì˜ ì‘í’ˆì…ë‹ˆë‹¤.\n",
      "\n",
      "í•œ ë‚¨ì„±ì¸ ë‹¤ë‹ˆì—˜ ë¸”ë ˆì´í¬ëŠ” ì‹¬ì¥ ìˆ˜ìˆ ì„ ë°›ì€ í›„, ì •ë¶€ì˜ ë³µì§€ ì‹œìŠ¤í…œì— ì˜í•´ ì–´ë ¤ì›€ì„ ê²ªê²Œ ë©ë‹ˆë‹¤. ê·¸ëŠ” ë³‘ìœ¼ë¡œ ì¸í•´ ì¼ì„ í•  ìˆ˜ ì—†ê²Œ ë˜ì§€ë§Œ, ì •ë¶€ì˜ ë³µì§€ ì‹œìŠ¤í…œì€ ê·¸ì˜ ìƒí™©ì„ ì œëŒ€ë¡œ ì´í•´í•˜ì§€ ëª»í•˜ê³ , ê·¸ë¥¼ ê³„ì†í•´ì„œ ê´´ë¡­í™ë‹ˆë‹¤. ì´ ì˜í™”ëŠ” ë‹¤ë‹ˆì—˜ ë¸”ë ˆì´í¬ì˜ ì´ì•¼ê¸°ë¥¼ í†µí•´ í˜„ëŒ€ ì‚¬íšŒì˜ ë¶ˆí‰ë“±ê³¼ ì¸ê°„ì˜ ì¡´ì—„ì„±ì„ ê°•ì¡°í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ì²´ì¸ 2: ì¤„ê±°ë¦¬ ìš”ì•½ (ì…ë ¥: ì˜í™” ì œëª© â†’ ì¶œë ¥: ì¤„ê±°ë¦¬)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1ì˜ ì¶œë ¥ì„ movie ë³€ìˆ˜ë¡œ ì „ë‹¬\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(chain2)\n",
    "\n",
    "# ì‹¤í–‰: \"SF\" ì¥ë¥´ì˜ ì˜í™” ì¶”ì²œ ë° ì¤„ê±°ë¦¬ ìš”ì•½\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\nğŸ”¹ ì˜í™” ì¤„ê±°ë¦¬ ìš”ì•½:\\n\", response) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb684fd",
   "metadata": {},
   "source": [
    "##### chain1ê³¼ chain2ì—ì„œ ì˜í™” ì œëª©ì´ ì¼ê´€ë˜ê²Œ ì „ë‹¬ ë˜ë„ë¡ ë³€ê²½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e6e622d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ì¶”ì²œëœ ì˜í™” (ì›ë³¸ ì‘ë‹µ): 'ì¡´ ìœ…'(2014)ì…ë‹ˆë‹¤.\n",
      "\n",
      "'ì¡´ ìœ…'ì€ í‚¬ë§ ì•¡ì…˜ ì˜í™”ì˜ ëŒ€í‘œì‘ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. ì´ ì˜í™”ëŠ” ì „ì§ ì•”ì‚´ì ì¡´ ìœ…(í‚¤ì•„ëˆ„ ë¦¬ë¸ŒìŠ¤)ì´ ì€í‡´ í›„ í‰í™”ë¡œìš´ ì‚¶ì„ ì‚´ê³  ìˆì§€ë§Œ, ìš°ì—°íˆ ê³¼ê±°ì˜ ì ë“¤ì—ê²Œ ë„ì „ì„ ë°›ê²Œ ë˜ë©´ì„œ ë²Œì–´ì§€ëŠ” ì´ì•¼ê¸°ë¥¼ ê·¸ë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ì´ ì˜í™”ëŠ” í™”ë ¤í•œ ì•¡ì…˜ê³¼ ë†’ì€ ìˆ˜ì¤€ì˜ ê²©íˆ¬ ì¥ë©´, ê·¸ë¦¬ê³  í‚¤ì•„ëˆ„ ë¦¬ë¸ŒìŠ¤ì˜ ë›°ì–´ë‚œ ì—°ê¸°ë ¥ìœ¼ë¡œ ë§ì€ íŒ¬ë“¤ì„ ì‚¬ë¡œì¡ì•˜ìŠµë‹ˆë‹¤. ë˜í•œ, ì´ ì˜í™”ëŠ” ì‹œë¦¬ì¦ˆë¡œ ì´ì–´ì ¸ 'ì¡´ ìœ…: 2'(2017), 'ì¡´ ìœ…: 3 - íŒŒë¼ë²¨ë£¸'(2019), 'ì¡´ ìœ…: 4'(2023)ê°€ ì¶œì‹œë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "'ì¡´ ìœ…'ì€ ì•¡ì…˜ ì˜í™” íŒ¬ë“¤ì—ê²Œ ê°•ë ¥í•˜ê²Œ ì¶”ì²œí•  ë§Œí•œ ì˜í™”ì…ë‹ˆë‹¤.\n",
      " ì¶”ì¶œëœ ì˜í™” ì œëª©: 'ì¡´\n",
      "\n",
      " ì˜í™” ì¤„ê±°ë¦¬ ìš”ì•½:\n",
      " To provide the information you requested, I need to follow these steps:\n",
      "\n",
      "\n",
      "\n",
      "## Step 1: Recommend a Movie\n",
      "First, I need to recommend a movie. Since I don't have a specific context or preference from you, I'll choose a popular and highly-regarded film: **Parasite (2019)**.\n",
      "\n",
      "\n",
      "\n",
      "## Step 2: Summarize the Movie in 3 Sentences\n",
      "Now, I'll summarize the movie \"Parasite\" in three sentences, changing the lines for clarity:\n",
      "\n",
      "The Kims, a poor family living in a cramped semi-basement apartment in Seoul, struggle to make ends meet. \n",
      "One day, the family's fortunes change when the son, Ki-woo, lands a tutoring job with a wealthy family, the Parks, posing as a university student. \n",
      "As the Kims infiltrate the Parks' lives, pretending to be unrelated, highly qualified individuals, they become embroiled in a complex class struggle that leads to unexpected and tragic consequences.\n",
      "\n",
      "\n",
      "\n",
      "## Step 3: Provide the Requested Information\n",
      "- **Movie Title:** Parasite (2019)\n",
      "- **Summary in 3 Sentences (with line change):**\n",
      "\n",
      "  The Kims, a poor family living in a cramped semi-basement apartment in Seoul, struggle to make ends meet.\n",
      "\n",
      "  One day, the family's fortunes change when the son, Ki-woo, lands a tutoring job with a wealthy family, the Parks, posing as a university student.\n",
      "\n",
      "  As the Kims infiltrate the Parks' lives, pretending to be unrelated, highly qualified individuals, they become embroiled in a complex class struggle that leads to unexpected and tragic consequences.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import re\n",
    "\n",
    "# Step 1: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¥ë¥´ì— ë”°ë¼ ì˜í™” ì¶”ì²œ\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} ì¥ë¥´ì—ì„œ ì¶”ì²œí•  ë§Œí•œ ì˜í™”ë¥¼ í•œ í¸ ì•Œë ¤ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# Step 2: ì¶”ì²œëœ ì˜í™”ì˜ ì¤„ê±°ë¦¬ë¥¼ ìš”ì•½\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} ì¶”ì²œí•œ ì˜í™”ì˜ ì œëª©ì„ ë¨¼ì € ì•Œë ¤ì£¼ì‹œê³ , ì¤„ì„ ë°”ê¾¸ì–´ì„œ ì˜í™”ì˜ ì¤„ê±°ë¦¬ë¥¼ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì‚¬ìš©\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# ì²´ì¸ 1: ì˜í™” ì¶”ì²œ (ì…ë ¥: ì¥ë¥´ â†’ ì¶œë ¥: ì˜í™” ì œëª©)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# Step 1: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¥ë¥´ì— ë”°ë¼ ì˜í™” ì¶”ì²œ\n",
    "movie_response = chain1.invoke({\"genre\": \"action\"})  # ì˜í™” ì œëª© ì–»ê¸°\n",
    "print(\" ì¶”ì²œëœ ì˜í™” (ì›ë³¸ ì‘ë‹µ):\", movie_response)\n",
    "\n",
    "#  ì˜í™” ì œëª©ë§Œ ì¶”ì¶œ (ì²« ë²ˆì§¸ í°ë”°ì˜´í‘œ ì•ˆì˜ ë¬¸ìì—´ ì°¾ê¸°)\n",
    "match = re.search(r'\"(.*?)\"', movie_response)\n",
    "if match:\n",
    "    movie_title = match.group(1)\n",
    "else:\n",
    "    movie_title = movie_response.split(\" \")[0]  # ëŒ€ì•ˆìœ¼ë¡œ ì²« ë²ˆì§¸ ë‹¨ì–´ ì‚¬ìš©\n",
    "\n",
    "print(\" ì¶”ì¶œëœ ì˜í™” ì œëª©:\", movie_title)\n",
    "\n",
    "# ì²´ì¸ 2: ì¤„ê±°ë¦¬ ìš”ì•½ (ì…ë ¥: ì˜í™” ì œëª© â†’ ì¶œë ¥: ì¤„ê±°ë¦¬)\n",
    "chain2 = prompt2 | llm | StrOutputParser()\n",
    "\n",
    "# ì‹¤í–‰: chain1ì˜ ì¶œë ¥(ì˜í™” ì œëª©)ì„ chain2ì— ëª…í™•íˆ ì „ë‹¬\n",
    "response = chain2.invoke({\"movie\": movie_title})\n",
    "print(\"\\n ì˜í™” ì¤„ê±°ë¦¬ ìš”ì•½:\\n\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da31790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "langchain-app-qc8Qb1Xk-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
