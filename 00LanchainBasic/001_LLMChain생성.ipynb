{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a",
   "metadata": {
    "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a"
   },
   "source": [
    "### LLM Chain ë§Œë“¤ê¸°\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9",
   "metadata": {
    "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9"
   },
   "source": [
    "## 1. í™˜ê²½ êµ¬ì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81",
   "metadata": {
    "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81"
   },
   "source": [
    "### 1) ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
    "outputId": "c96ed02d-19b7-4e90-d92e-1ae52895e303"
   },
   "outputs": [],
   "source": [
    "#%pip install -q langchain langchain-openai dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55152049-e9e5-4952-8e19-409f58cf3ac9",
   "metadata": {
    "id": "55152049-e9e5-4952-8e19-409f58cf3ac9"
   },
   "source": [
    "### 2) OpenAI ì¸ì¦í‚¤ ì„¤ì •\n",
    "https://openai.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b76f68a8-4745-4377-8057-6090b87377d1",
   "metadata": {
    "id": "b76f68a8-4745-4377-8057-6090b87377d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ì„œ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e09aaca6-5aa2-4b52-bbfc-196e808dc5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.26\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c",
   "metadata": {
    "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c"
   },
   "source": [
    "## 2. LLM Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23729d10-9600-415b-b7d1-f954665224e3",
   "metadata": {
    "id": "23729d10-9600-415b-b7d1-f954665224e3"
   },
   "source": [
    "### 1) Prompt + LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "on0y4xF8VoyE",
   "metadata": {
    "id": "on0y4xF8VoyE"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# chain ì‹¤í–‰\n",
    "result = llm.invoke(\"ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ì— ëŒ€í•˜ì—¬ ì‰½ê²Œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.\")\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc4accf-c927-40a3-ba2c-f891c94c34f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WzcZy4PruV1n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "WzcZy4PruV1n",
    "outputId": "18ecc8f9-5748-4b16-cb07-4a0f7a01fb5a"
   },
   "outputs": [],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c97fc",
   "metadata": {},
   "source": [
    "### 2) PromptTemplate + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SeNi_VXqYD-b",
   "metadata": {
    "id": "SeNi_VXqYD-b"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}ì— ëŒ€í•´ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01WLucSpYjZt",
   "metadata": {
    "id": "01WLucSpYjZt"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# chain ì—°ê²° (LCEL)\n",
    "chain = prompt | llm\n",
    "print(type(chain))\n",
    "\n",
    "# chain í˜¸ì¶œ\n",
    "result = chain.invoke({\"input\": \"ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬\"})\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170ec878",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56848a4c",
   "metadata": {},
   "source": [
    "### 3) PromptTemplate + LLM(invoke()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1e9009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. ì»´í¬ë„ŒíŠ¸ ì •ì˜\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}ì— ëŒ€í•´ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AIì™€ ë™ì¼í•œ ëª¨ë¸\n",
    "    temperature=0.7)\n",
    "\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 2. chain ìƒì„± (LCEL)\n",
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "\n",
    "# 3. chainì˜ invoke í˜¸ì¶œ\n",
    "result = chain.invoke({\"input\": \"ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬\"})\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ca7cdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ëŠ” ì‚¬ëŒì˜ ë‡Œê°€ í•™ìŠµí•˜ëŠ” ì›ë¦¬ì™€ ìœ ì‚¬í•©ë‹ˆë‹¤. ì»´í“¨í„°ì—å¤§é‡çš„ ë°ì´í„°ë¥¼ ì œê³µí•˜ê³ , ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ íŒ¨í„´ì„ ì°¾ê³ , íŒ¨í„´ì„ ê¸°ë°˜ìœ¼ë¡œ ì˜ˆì¸¡ì´ë‚˜ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
      "\n",
      "êµ¬ì²´ì ìœ¼ë¡œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê³¼ì •ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.\n",
      "\n",
      "1. **ë°ì´í„° ìˆ˜ì§‘**: ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•´å¤§é‡çš„ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤. ì´ ë°ì´í„°ëŠ” ë¬¸ì œì— ë”°ë¼ ë‹¤ë¥´ì§€ë§Œ, ì´ë¯¸ì§€, í…ìŠ¤íŠ¸, ì˜¤ë””ì˜¤ ë“± ë‹¤ì–‘í•œ í˜•íƒœì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **ë°ì´í„° ì „ì²˜ë¦¬**: ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê¸° ì‰½ê²Œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ë°ì´í„°ë¥¼ ì •ì œí•˜ê³ , í•„ìš”í•œ ê²½ìš° ë°ì´í„°ë¥¼ ë³€í™˜í•˜ê±°ë‚˜ íŠ¹ì§•ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
      "\n",
      "3. **ëª¨ë¸ ì •ì˜**: ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì„ ì •ì˜í•©ë‹ˆë‹¤. ëª¨ë¸ì€ ë°ì´í„°ë¡œë¶€í„° íŒ¨í„´ì„ í•™ìŠµí•˜ê³ , ì˜ˆì¸¡ì´ë‚˜ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤. ì‹ ê²½ë§, ê²°ì • íŠ¸ë¦¬, ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹  ë“± ë‹¤ì–‘í•œ ëª¨ë¸ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "4. **í•™ìŠµ**: ëª¨ë¸ì— ë°ì´í„°ë¥¼ ì œê³µí•˜ê³ , ëª¨ë¸ì´ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ íŒ¨í„´ì„ í•™ìŠµí•˜ë„ë¡ í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œ ëª¨ë¸ì€ ë°ì´í„°ë¥¼ í†µí•´ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ë©°, ìµœì ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ìŠµë‹ˆë‹¤.\n",
      "\n",
      "5. **í‰ê°€**: í•™ìŠµëœ ëª¨ë¸ì„ í‰ê°€í•©ë‹ˆë‹¤. í‰ê°€ ë°ì´í„°ì— ëª¨ë¸ì„ ì ìš©í•˜ì—¬ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê³ , í•„ìš”ì— ë”°ë¼ ëª¨ë¸ì„ ì¡°ì •í•©ë‹ˆë‹¤.\n",
      "\n",
      "6. **ì˜ˆì¸¡ ë˜ëŠ” ë¶„ë¥˜**: í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ì´ë‚˜ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì˜ˆë¥¼ ë“¤ì–´, ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” ê²½ìš°ë¥¼ ìƒê°í•´ ë´…ì‹œë‹¤. ê³ ì–‘ì´ì™€ ê°•ì•„ì§€ì˜ ì´ë¯¸ì§€ë¥¼ ì»´í“¨í„°ì— ì œê³µí•˜ê³ , ì»´í“¨í„°ëŠ” ì´ë¯¸ì§€ì˜ íŠ¹ì§•ì„ ë¶„ì„í•˜ì—¬ ê³ ì–‘ì´ì™€ ê°•ì•„ì§€ë¥¼ êµ¬ë¶„í•˜ëŠ” ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤. ì´ ê³¼ì •ì„ í†µí•´ ì»´í“¨í„°ëŠ” ê³ ì–‘ì´ì™€ ê°•ì•„ì§€ì˜ íŒ¨í„´ì„ í•™ìŠµí•˜ê³ , ìƒˆë¡œìš´ ì´ë¯¸ì§€ê°€ ì£¼ì–´ì¡Œì„ ë•Œ ì´ë¥¼ ë¶„ë¥˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ¬í•œ í•™ìŠµ ì›ë¦¬ëŠ” ë‹¤ì–‘í•œ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì— ì ìš©ë˜ë©°, ì´ë¥¼ í†µí•´ ì»´í“¨í„°ëŠ” ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³ , ì˜ˆì¸¡ì´ë‚˜ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ëŠ” ëŠ¥ë ¥ì„ ê°–ê²Œ ë©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d997b16",
   "metadata": {},
   "source": [
    "### 4) PromptTemplate + LLM(stream()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684654e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ëŠ” ì‚¬ëŒì˜ ë‡Œê°€ í•™ìŠµí•˜ëŠ” ì›ë¦¬ì™€ ìœ ì‚¬í•©ë‹ˆë‹¤. \n",
      "\n",
      "1. **ë°ì´í„° ìˆ˜ì§‘**: ìš°ì„  ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•´ì„œëŠ” ìˆ˜ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤. \n",
      "\n",
      "2. **ë°ì´í„° ì…ë ¥**: ì´ ë°ì´í„°ë¥¼ ëª¨ë¸ì— ì…ë ¥í•©ë‹ˆë‹¤. \n",
      "\n",
      "3. **ì˜ˆì¸¡**: ëª¨ë¸ì€ ì…ë ¥ëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. \n",
      "\n",
      "4. **ì˜¤ì°¨ ê³„ì‚°**: ì˜ˆì¸¡ ê²°ê³¼ì™€ ì‹¤ì œ ê²°ê³¼ì˜ ì°¨ì´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ì´ë¥¼ 'ì˜¤ì°¨'ë¼ê³  í•©ë‹ˆë‹¤. \n",
      "\n",
      "5. **ëª¨ë¸ ì—…ë°ì´íŠ¸**: ì´ ì˜¤ì°¨ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëª¨ë¸ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤. ì¦‰, ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •í•˜ì—¬ ë‹¤ìŒ ì˜ˆì¸¡ì—ì„œëŠ” ë” ì •í™•í•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n",
      "\n",
      "6. **ë°˜ë³µ**: ì´ ê³¼ì •ì„ ë§¤ìš° ë§ì€ ë°ì´í„°ì— ëŒ€í•´ ë°˜ë³µ ìˆ˜í–‰í•©ë‹ˆë‹¤. \n",
      "\n",
      "ì´ë ‡ê²Œ ë°˜ë³µ í•™ìŠµì„ í†µí•´ ëª¨ë¸ì€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì˜ˆì¸¡í•˜ëŠ” ëŠ¥ë ¥ì„ í‚¤ìš°ê²Œ ë©ë‹ˆë‹¤. \n",
      "\n",
      "ì˜ˆë¥¼ ë“¤ì–´, ê³ ì–‘ì´ ì‚¬ì§„ìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ì—ê²Œ ìƒˆë¡œìš´ ê³ ì–‘ì´ ì‚¬ì§„ì„ ë³´ì—¬ì£¼ë©´, ëª¨ë¸ì€ ì´ì „ì— ë³´ì§€ ëª»í•œ ì‚¬ì§„ì´ì§€ë§Œ ê³ ì–‘ì´ë¼ëŠ” ê²ƒì„ ì¸ì‹í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "ì´ì²˜ëŸ¼ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì€ ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ í†µí•´ ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ê³ , ìƒˆë¡œìš´ ìƒí™©ì— ëŒ€ì²˜í•˜ëŠ” ëŠ¥ë ¥ì„ í‚¤ìš°ëŠ” ê²ƒì…ë‹ˆë‹¤."
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. ì»´í¬ë„ŒíŠ¸ ì •ì˜\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}ì— ëŒ€í•´ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AIì™€ ë™ì¼í•œ ëª¨ë¸\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "\n",
    "# chain ì—°ê²° (LCEL)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ì„ ìœ„í•œ ìš”ì²­\n",
    "answer = chain.stream({\"input\": \"ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬\"})\n",
    "# ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥\n",
    "#print(answer)\n",
    "\n",
    "for token in answer:\n",
    "    # ìŠ¤íŠ¸ë¦¼ì—ì„œ ë°›ì€ ë°ì´í„°ì˜ ë‚´ìš©ì„ ì¶œë ¥í•©ë‹ˆë‹¤. ì¤„ë°”ê¿ˆ ì—†ì´ ì´ì–´ì„œ ì¶œë ¥í•˜ê³ , ë²„í¼ë¥¼ ì¦‰ì‹œ ë¹„ì›ë‹ˆë‹¤.\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0188674-915f-41af-ac46-56f9f54289b0",
   "metadata": {
    "id": "b0188674-915f-41af-ac46-56f9f54289b0"
   },
   "source": [
    "##### 2) Multiple Chains\n",
    "* Multi Chainì„ í™œìš©í•œ ì˜í™” ì¶”ì²œ ë° ì¤„ê±°ë¦¬ ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
    "outputId": "7ee83878-5d1a-45e3-f033-100da33f3ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ì¶”ì²œëœ ì˜í™”: **'The Pursuit of Happyness'** \n",
      "\n",
      "*   **ì¥ë¥´**: ë“œë¼ë§ˆ/ì „ê¸°\n",
      "*   **ê°ë…**: ê°€ë¸Œë¦¬ì—˜ ë®ˆì§€ë…¸\n",
      "*   **ì¶œì—°**: ìœŒ ìŠ¤ë¯¸ìŠ¤, ì œì´ë“  ìŠ¤ë¯¸ìŠ¤, í‹°ë‚˜ ë©”ì´ì €, ì¤„ë¦¬ì–¸ í˜¸í”„, ë¸Œë¼ì´ì–¸ ìŠ¤í…ŒíŒŒë‹‰\n",
      "*   **ê°œë´‰ì¼**: 2006ë…„ 12ì›” 15ì¼\n",
      "*   **ë‚´ìš©**: í¬ë¦¬ìŠ¤ ê°€ë“œë„ˆëŠ” ì„±ê³µí•œ ì£¼ì‹ ì¤‘ê°œì¸ì´ë‹¤. ê·¸ëŸ¬ë‚˜ ê°‘ìê¸° ì§ì¥ì„ ìƒê³ , ì™¸ì•„ë“¤ í¬ë¦¬ìŠ¤í† í¼ì™€ í•¨ê»˜ ë…¸ìˆ™ì ì‰¼í„°ì—ì„œ ì‚´ê²Œ ëœë‹¤. í¬ë¦¬ìŠ¤ ê°€ë“œë„ˆëŠ” ë‹¤ì‹œ ì§ì—…ì„ ì–»ê³ ì í•˜ì§€ë§Œ, ì‰½ì§€ ì•Šë‹¤. í¬ë¦¬ìŠ¤ ê°€ë“œë„ˆëŠ” í¬ë¦¬ìŠ¤í† í¼ë¥¼ ìœ„í•´ì„œë¼ë„, ë‹¤ì‹œ ì£¼ì‹ ì¤‘ê°œì¸ì´ ë˜ê³ ì í•œë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¥ë¥´ì— ë”°ë¼ ì˜í™” ì¶”ì²œ\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} ì¥ë¥´ì—ì„œ ì¶”ì²œí•  ë§Œí•œ ì˜í™”ë¥¼ í•œ í¸ ì•Œë ¤ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# Step 2: ì¶”ì²œëœ ì˜í™”ì˜ ì¤„ê±°ë¦¬ë¥¼ ìš”ì•½\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} ì¶”ì „í•œ ì˜í™”ì˜ ì œëª©ì„ ë¨¼ì € ì•Œë ¤ì£¼ì‹œê³ , ì¤„ì„ ë°”ê¾¸ì–´ì„œ ì˜í™”ì˜ ì¤„ê±°ë¦¬ë¥¼ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì‚¬ìš©\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AIì™€ ë™ì¼í•œ ëª¨ë¸\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# ì²´ì¸ 1: ì˜í™” ì¶”ì²œ (ì…ë ¥: ì¥ë¥´ â†’ ì¶œë ¥: ì˜í™” ì œëª©)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# Step 1: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¥ë¥´ì— ë”°ë¼ ì˜í™” ì¶”ì²œ\n",
    "movie = chain1.invoke({\"genre\": \"Drama\"})  # ì˜í™” ì œëª© ì–»ê¸°\n",
    "print(\" ì¶”ì²œëœ ì˜í™”:\", movie)  # movie ê°’ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16718b76-f59d-48f7-906f-5d2371417803",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "16718b76-f59d-48f7-906f-5d2371417803",
    "outputId": "6e3371cd-d294-4be7-a868-2eae5ee6e5de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first={\n",
      "  movie: ChatPromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, template='{genre} ì¥ë¥´ì—ì„œ ì¶”ì²œí•  ë§Œí•œ ì˜í™”ë¥¼ í•œ í¸ ì•Œë ¤ì£¼ì„¸ìš”.'), additional_kwargs={})])\n",
      "         | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000211FED74B60>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000211FE5DFE00>, root_client=<openai.OpenAI object at 0x00000211FED73860>, root_async_client=<openai.AsyncOpenAI object at 0x00000211FE396840>, model_name='meta-llama/llama-4-scout-17b-16e-instruct', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "         | StrOutputParser()\n",
      "} middle=[ChatPromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, template='{movie} ì¶”ì „í•œ ì˜í™”ì˜ ì œëª©ì„ ë¨¼ì € ì•Œë ¤ì£¼ì‹œê³ , ì¤„ì„ ë°”ê¾¸ì–´ì„œ ì˜í™”ì˜ ì¤„ê±°ë¦¬ë¥¼ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.'), additional_kwargs={})]), ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000211FED74B60>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000211FE5DFE00>, root_client=<openai.OpenAI object at 0x00000211FED73860>, root_async_client=<openai.AsyncOpenAI object at 0x00000211FE396840>, model_name='meta-llama/llama-4-scout-17b-16e-instruct', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n",
      "\n",
      "ğŸ”¹ ì˜í™” ì¤„ê±°ë¦¬ ìš”ì•½:\n",
      " The movie I recommend is 'ì˜¬ë“œ ë³´ì´'(Oldboy, 2003).\n",
      "\n",
      "Here is a summary of the movie in three sentences:\n",
      "\n",
      "The movie 'ì˜¬ë“œ ë³´ì´'(Oldboy, 2003) tells the story of ì˜¤ëŒ€ìˆ˜, a man who is kidnapped and imprisoned for 15 years. After his sudden release, he sets out to uncover the truth about his past and the secrets surrounding his imprisonment. Through his journey, he experiences a complex mix of emotions and ultimately finds a shocking revelation that changes his life forever.\n"
     ]
    }
   ],
   "source": [
    "# ì²´ì¸ 2: ì¤„ê±°ë¦¬ ìš”ì•½ (ì…ë ¥: ì˜í™” ì œëª© â†’ ì¶œë ¥: ì¤„ê±°ë¦¬)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1ì˜ ì¶œë ¥ì„ movie ë³€ìˆ˜ë¡œ ì „ë‹¬\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(chain2)\n",
    "\n",
    "# ì‹¤í–‰: \"SF\" ì¥ë¥´ì˜ ì˜í™” ì¶”ì²œ ë° ì¤„ê±°ë¦¬ ìš”ì•½\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\nğŸ”¹ ì˜í™” ì¤„ê±°ë¦¬ ìš”ì•½:\\n\", response) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb684fd",
   "metadata": {},
   "source": [
    "##### chain1ê³¼ chain2ì—ì„œ ì˜í™” ì œëª©ì´ ì¼ê´€ë˜ê²Œ ì „ë‹¬ ë˜ë„ë¡ ë³€ê²½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e6e622d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ì¶”ì²œëœ ì˜í™” (ì›ë³¸ ì‘ë‹µ): 'ì˜¬ë“œë³´ì´'(Oldboy, 2003)ëŠ” ëŒ€í•œë¯¼êµ­ì˜ ë“œë¼ë§ˆ ì˜í™”ì…ë‹ˆë‹¤. \n",
      "\n",
      "ë°•ì°¬ìš± ê°ë…ì´ ì—°ì¶œí•˜ê³ , ìµœë¯¼ì‹, ìœ ì˜¤ì„±, ê°•í˜œì • ë“±ì´ ì¶œì—°í•©ë‹ˆë‹¤.\n",
      "\n",
      "ë‚©ì¹˜ëœ ì§€ 15ë…„ ë§Œì— í’€ë ¤ë‚œ ì£¼ì¸ê³µ ì˜¤ëŒ€ìˆ˜(ìµœë¯¼ì‹ ë¶„)ëŠ” ìì‹ ê³¼ ê°€ì¡±ì„ ë‚©ì¹˜í•œ ì‚¬ëŒì˜ ì •ì²´ì™€ ì´ìœ ë¥¼ ì°¾ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ê·¸ëŸ¬ë˜ ì¤‘, ìì‹ ê³¼ ë˜‘ê°™ì€ ë°©ë²•ìœ¼ë¡œ 15ë…„ê°„ ê°ê¸ˆëœ í”¼í•´ìë¥¼ ë§Œë‚˜ë©´ì„œ ì§„ì‹¤ì„ ì¶”ì í•˜ê¸° ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì´ ì˜í™”ëŠ” ì¸ê°„ì˜ ë³¸ì„±ê³¼ ë³µìˆ˜ì‹¬ì— ëŒ€í•œ ê¹Šì€ íƒêµ¬ë¥¼ í†µí•´, ì¸ê°„ì˜ ì‹¬ì˜¤í•œ ë‚´ë©´ì„¸ê³„ë¥¼ í‘œí˜„í•©ë‹ˆë‹¤.\n",
      "\n",
      "'ì˜¬ë“œë³´ì´'ëŠ” ì¹¸ ì˜í™”ì œì—ì„œ ê°ë… ì£¼ì—°ì¸ ìµœë¯¼ì‹ì´ 'ìµœìš°ìˆ˜ ë‚¨ìš°ì£¼ì—°ìƒ'ì„ ìˆ˜ìƒí•˜ëŠ” ë“±, êµ­ë‚´ì™¸ì—ì„œ ë§ì€ ì°¬ì‚¬ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ê°•ë ¬í•œ ìŠ¤í† ë¦¬ì™€ ì—°ì¶œ, ë°°ìš°ë“¤ì˜ ì—°ê¸°ë¡œ ë§ì€ ì‚¬ëŒë“¤ì—ê²Œ ê°•í•œ ì¸ìƒì„ ë‚¨ê¸´ ì˜í™”ì…ë‹ˆë‹¤.\n",
      " ì¶”ì¶œëœ ì˜í™” ì œëª©: 'ì˜¬ë“œë³´ì´'(Oldboy,\n",
      "\n",
      " ì˜í™” ì¤„ê±°ë¦¬ ìš”ì•½:\n",
      " **ì˜¬ë“œë³´ì´**\n",
      "\n",
      "'ì˜¬ë“œë³´ì´'ëŠ” ì£¼ì¸ê³µ ì˜¤ëŒ€ìˆ˜(ìµœë¯¼ì‹ ë¶„)ê°€ 15ë…„ê°„ì˜ ë‚©ì¹˜ì™€ ê°ê¸ˆ ìƒí™œì„ ê²ªì€ ë’¤, ìì‹ ì˜ ë‚©ì¹˜ë²”ì„ ì°¾ì•„ ë³µìˆ˜í•˜ëŠ” ë‚´ìš©ì˜ ì˜í™”ì…ë‹ˆë‹¤. ì˜¤ëŒ€ìˆ˜ëŠ” ìì‹ ì´ ê°‡í˜€ ìˆë˜ ê³³ì—ì„œ íƒˆì¶œí•œ ë’¤, ìì‹ ì˜ ë‚©ì¹˜ë²”ì¸ ì´ìš°ì§„(ìœ í•´ì§„ ë¶„)ì„ ì°¾ì•„ë‚˜ì„œê³ , ì´ìš°ì§„ì€ ì˜¤ëŒ€ìˆ˜ì—ê²Œ ìì‹ ì˜ ë¹„ë°€ì„ ì•Œë ¤ì£¼ë©° ë³µìˆ˜ë¥¼ ë¶€ì¶”ê¹ë‹ˆë‹¤. ì˜¤ëŒ€ìˆ˜ëŠ” ì´ìš°ì§„ì— ëŒ€í•œ ë³µìˆ˜ë¥¼ ìœ„í•´ ì—¬ëŸ¬ì‚¬ëŒì„ ì£½ì´ë©´ì„œê¹Œì§€ ì°¾ì•„ê°€ëŠ”ë°, ì´ìš°ì§„ì˜ ë¹„ë°€ì€ ì˜¤ëŒ€ìˆ˜ì˜  ë”¸ê³¼ ê´€ë ¨ë˜ì–´ ìˆì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import re\n",
    "\n",
    "# Step 1: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¥ë¥´ì— ë”°ë¼ ì˜í™” ì¶”ì²œ\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} ì¥ë¥´ì—ì„œ ì¶”ì²œí•  ë§Œí•œ ì˜í™”ë¥¼ í•œ í¸ ì•Œë ¤ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# Step 2: ì¶”ì²œëœ ì˜í™”ì˜ ì¤„ê±°ë¦¬ë¥¼ ìš”ì•½\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} ì¶”ì²œí•œ ì˜í™”ì˜ ì œëª©ì„ ë¨¼ì € ì•Œë ¤ì£¼ì‹œê³ , ì¤„ì„ ë°”ê¾¸ì–´ì„œ ì˜í™”ì˜ ì¤„ê±°ë¦¬ë¥¼ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì‚¬ìš©\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# ì²´ì¸ 1: ì˜í™” ì¶”ì²œ (ì…ë ¥: ì¥ë¥´ â†’ ì¶œë ¥: ì˜í™” ì œëª©)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# Step 1: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¥ë¥´ì— ë”°ë¼ ì˜í™” ì¶”ì²œ\n",
    "movie_response = chain1.invoke({\"genre\": \"Drama\"})  # ì˜í™” ì œëª© ì–»ê¸°\n",
    "print(\" ì¶”ì²œëœ ì˜í™” (ì›ë³¸ ì‘ë‹µ):\", movie_response)\n",
    "\n",
    "#  ì˜í™” ì œëª©ë§Œ ì¶”ì¶œ (ì²« ë²ˆì§¸ í°ë”°ì˜´í‘œ ì•ˆì˜ ë¬¸ìì—´ ì°¾ê¸°)\n",
    "match = re.search(r'\"(.*?)\"', movie_response)\n",
    "if match:\n",
    "    movie_title = match.group(1)\n",
    "else:\n",
    "    movie_title = movie_response.split(\" \")[0]  # ëŒ€ì•ˆìœ¼ë¡œ ì²« ë²ˆì§¸ ë‹¨ì–´ ì‚¬ìš©\n",
    "\n",
    "print(\" ì¶”ì¶œëœ ì˜í™” ì œëª©:\", movie_title)\n",
    "\n",
    "# ì²´ì¸ 2: ì¤„ê±°ë¦¬ ìš”ì•½ (ì…ë ¥: ì˜í™” ì œëª© â†’ ì¶œë ¥: ì¤„ê±°ë¦¬)\n",
    "chain2 = prompt2 | llm | StrOutputParser()\n",
    "\n",
    "# ì‹¤í–‰: chain1ì˜ ì¶œë ¥(ì˜í™” ì œëª©)ì„ chain2ì— ëª…í™•íˆ ì „ë‹¬\n",
    "response = chain2.invoke({\"movie\": movie_title})\n",
    "print(\"\\n ì˜í™” ì¤„ê±°ë¦¬ ìš”ì•½:\\n\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da31790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "langchain-app-qc8Qb1Xk-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
