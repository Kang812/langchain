{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a",
   "metadata": {
    "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a"
   },
   "source": [
    "### LLM Chain 만들기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9",
   "metadata": {
    "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9"
   },
   "source": [
    "## 1. 환경 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81",
   "metadata": {
    "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81"
   },
   "source": [
    "### 1) 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
    "outputId": "c96ed02d-19b7-4e90-d92e-1ae52895e303"
   },
   "outputs": [],
   "source": [
    "#%pip install -q langchain langchain-openai dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55152049-e9e5-4952-8e19-409f58cf3ac9",
   "metadata": {
    "id": "55152049-e9e5-4952-8e19-409f58cf3ac9"
   },
   "source": [
    "### 2) OpenAI 인증키 설정\n",
    "https://openai.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b76f68a8-4745-4377-8057-6090b87377d1",
   "metadata": {
    "id": "b76f68a8-4745-4377-8057-6090b87377d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e09aaca6-5aa2-4b52-bbfc-196e808dc5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.26\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c",
   "metadata": {
    "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c"
   },
   "source": [
    "## 2. LLM Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23729d10-9600-415b-b7d1-f954665224e3",
   "metadata": {
    "id": "23729d10-9600-415b-b7d1-f954665224e3"
   },
   "source": [
    "### 1) Prompt + LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "on0y4xF8VoyE",
   "metadata": {
    "id": "on0y4xF8VoyE"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# chain 실행\n",
    "result = llm.invoke(\"인공지능 모델의 학습 원리에 대하여 쉽게 설명해 주세요.\")\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc4accf-c927-40a3-ba2c-f891c94c34f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WzcZy4PruV1n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "WzcZy4PruV1n",
    "outputId": "18ecc8f9-5748-4b16-cb07-4a0f7a01fb5a"
   },
   "outputs": [],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c97fc",
   "metadata": {},
   "source": [
    "### 2) PromptTemplate + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SeNi_VXqYD-b",
   "metadata": {
    "id": "SeNi_VXqYD-b"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01WLucSpYjZt",
   "metadata": {
    "id": "01WLucSpYjZt"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm\n",
    "print(type(chain))\n",
    "\n",
    "# chain 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170ec878",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56848a4c",
   "metadata": {},
   "source": [
    "### 3) PromptTemplate + LLM(invoke()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1e9009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7)\n",
    "\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 2. chain 생성 (LCEL)\n",
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "\n",
    "# 3. chain의 invoke 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ca7cdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 컴퓨터에大量的 데이터를 제공하고, 데이터를 분석하여 패턴을 찾고, 패턴을 기반으로 예측이나 분류를 수행하는 것입니다.\n",
      "\n",
      "구체적으로는 다음과 같은 과정으로 학습합니다.\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델을 학습시키기 위해大量的 데이터를 수집합니다. 이 데이터는 문제에 따라 다르지만, 이미지, 텍스트, 오디오 등 다양한 형태일 수 있습니다.\n",
      "\n",
      "2. **데이터 전처리**: 수집한 데이터를 분석하기 쉽게 변환하는 과정입니다. 데이터를 정제하고, 필요한 경우 데이터를 변환하거나 특징을 추출합니다.\n",
      "\n",
      "3. **모델 정의**: 인공지능 모델을 정의합니다. 모델은 데이터로부터 패턴을 학습하고, 예측이나 분류를 수행하는 알고리즘입니다. 신경망, 결정 트리, 서포트 벡터 머신 등 다양한 모델이 있습니다.\n",
      "\n",
      "4. **학습**: 모델에 데이터를 제공하고, 모델이 데이터를 분석하여 패턴을 학습하도록 합니다. 이 과정에서 모델은 데이터를 통해 파라미터를 조정하며, 최적의 파라미터를 찾습니다.\n",
      "\n",
      "5. **평가**: 학습된 모델을 평가합니다. 평가 데이터에 모델을 적용하여 성능을 측정하고, 필요에 따라 모델을 조정합니다.\n",
      "\n",
      "6. **예측 또는 분류**: 학습된 모델을 사용하여 새로운 데이터에 대한 예측이나 분류를 수행합니다.\n",
      "\n",
      "예를 들어, 이미지 분류 모델을 학습시키는 경우를 생각해 봅시다. 고양이와 강아지의 이미지를 컴퓨터에 제공하고, 컴퓨터는 이미지의 특징을 분석하여 고양이와 강아지를 구분하는 모델을 학습합니다. 이 과정을 통해 컴퓨터는 고양이와 강아지의 패턴을 학습하고, 새로운 이미지가 주어졌을 때 이를 분류할 수 있습니다.\n",
      "\n",
      "이러한 학습 원리는 다양한 인공지능 모델에 적용되며, 이를 통해 컴퓨터는 데이터를 분석하고, 예측이나 분류를 수행하는 능력을 갖게 됩니다.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d997b16",
   "metadata": {},
   "source": [
    "### 4) PromptTemplate + LLM(stream()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684654e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. \n",
      "\n",
      "1. **데이터 수집**: 우선 인공지능 모델을 학습시키기 위해서는 수많은 데이터가 필요합니다. \n",
      "\n",
      "2. **데이터 입력**: 이 데이터를 모델에 입력합니다. \n",
      "\n",
      "3. **예측**: 모델은 입력된 데이터를 바탕으로 예측을 수행합니다. \n",
      "\n",
      "4. **오차 계산**: 예측 결과와 실제 결과의 차이를 계산합니다. 이를 '오차'라고 합니다. \n",
      "\n",
      "5. **모델 업데이트**: 이 오차를 바탕으로 모델을 업데이트합니다. 즉, 모델의 가중치를 조정하여 다음 예측에서는 더 정확한 결과를 얻을 수 있도록 합니다.\n",
      "\n",
      "6. **반복**: 이 과정을 매우 많은 데이터에 대해 반복 수행합니다. \n",
      "\n",
      "이렇게 반복 학습을 통해 모델은 데이터를 분석하고 예측하는 능력을 키우게 됩니다. \n",
      "\n",
      "예를 들어, 고양이 사진으로 학습된 모델에게 새로운 고양이 사진을 보여주면, 모델은 이전에 보지 못한 사진이지만 고양이라는 것을 인식할 수 있습니다. \n",
      "\n",
      "이처럼 인공지능 모델은 주어진 데이터를 통해 스스로 학습하고, 새로운 상황에 대처하는 능력을 키우는 것입니다."
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "# 스트리밍 출력\n",
    "#print(answer)\n",
    "\n",
    "for token in answer:\n",
    "    # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0188674-915f-41af-ac46-56f9f54289b0",
   "metadata": {
    "id": "b0188674-915f-41af-ac46-56f9f54289b0"
   },
   "source": [
    "##### 2) Multiple Chains\n",
    "* Multi Chain을 활용한 영화 추천 및 줄거리 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
    "outputId": "7ee83878-5d1a-45e3-f033-100da33f3ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 추천된 영화: '루카' (2021)는 이탈리아 애니메이션 드라마 영화입니다. 11살 소년 루카는 바다 괴물로 살고 있습니다. 그는 인간 세계에 대한 호기심이 많고, 친구를 사귀고 싶어 합니다. 루카는 여름을 보내기 위해 바다 근처의 작은 마을로 이동합니다. 그곳에서 그는 알베르토라는 소년과 친해집니다. 알베르토는 루카와 같은 바다 괴물입니다. 두 사람은 인간으로 변장하고 마을 사람들과 어울립니다. 하지만 그들의 비밀은 위험에 처하게 됩니다.\n",
      "\n",
      "이 영화는 아름다운 애니메이션과 감동적인 이야기로 많은 사랑을 받았습니다. 바다 괴물이라는 독특한 설정과 이탈리아 문화를 배경으로 한 이야기는 관객들에게 새로운 경험을 제공합니다. 또한, 우정과 성장에 대한 이야기는 모든 연령대의 관객에게 감동을 줄 것입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추전한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 줄거리를 3문장으로 요약해 주세요.\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "movie = chain1.invoke({\"genre\": \"Drama\"})  # 영화 제목 얻기\n",
    "print(\" 추천된 영화:\", movie)  # movie 값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16718b76-f59d-48f7-906f-5d2371417803",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "16718b76-f59d-48f7-906f-5d2371417803",
    "outputId": "6e3371cd-d294-4be7-a868-2eae5ee6e5de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first={\n",
      "  movie: ChatPromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, template='{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.'), additional_kwargs={})])\n",
      "         | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000211FE707590>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000211FE5E9310>, root_client=<openai.OpenAI object at 0x00000211F88BE480>, root_async_client=<openai.AsyncOpenAI object at 0x00000211FE7062A0>, model_name='meta-llama/llama-4-scout-17b-16e-instruct', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "         | StrOutputParser()\n",
      "} middle=[ChatPromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, template='{movie} 추전한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 줄거리를 3문장으로 요약해 주세요.'), additional_kwargs={})]), ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000211FE707590>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000211FE5E9310>, root_client=<openai.OpenAI object at 0x00000211F88BE480>, root_async_client=<openai.AsyncOpenAI object at 0x00000211FE7062A0>, model_name='meta-llama/llama-4-scout-17b-16e-instruct', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n",
      "\n",
      "🔹 영화 줄거리 요약:\n",
      " \"나는 다니엘 블레이크\"는 켄 로치 감독의 작품입니다.\n",
      "\n",
      "한 남성인 다니엘 블레이크는 심장 수술을 받은 후, 정부의 복지 시스템에 의해 어려움을 겪게 됩니다. 그는 병으로 인해 일을 할 수 없게 되지만, 정부의 복지 시스템은 그의 상황을 제대로 이해하지 못하고, 그를 계속해서 괴롭힙니다. 이 영화는 다니엘 블레이크의 이야기를 통해 현대 사회의 불평등과 인간의 존엄성을 강조합니다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(chain2)\n",
    "\n",
    "# 실행: \"SF\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\\n\", response) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb684fd",
   "metadata": {},
   "source": [
    "##### chain1과 chain2에서 영화 제목이 일관되게 전달 되도록 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e6e622d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 추천된 영화 (원본 응답): '존 윅'(2014)입니다.\n",
      "\n",
      "'존 윅'은 킬링 액션 영화의 대표작 중 하나입니다. 이 영화는 전직 암살자 존 윅(키아누 리브스)이 은퇴 후 평화로운 삶을 살고 있지만, 우연히 과거의 적들에게 도전을 받게 되면서 벌어지는 이야기를 그립니다.\n",
      "\n",
      "이 영화는 화려한 액션과 높은 수준의 격투 장면, 그리고 키아누 리브스의 뛰어난 연기력으로 많은 팬들을 사로잡았습니다. 또한, 이 영화는 시리즈로 이어져 '존 윅: 2'(2017), '존 윅: 3 - 파라벨룸'(2019), '존 윅: 4'(2023)가 출시되었습니다.\n",
      "\n",
      "'존 윅'은 액션 영화 팬들에게 강력하게 추천할 만한 영화입니다.\n",
      " 추출된 영화 제목: '존\n",
      "\n",
      " 영화 줄거리 요약:\n",
      " To provide the information you requested, I need to follow these steps:\n",
      "\n",
      "\n",
      "\n",
      "## Step 1: Recommend a Movie\n",
      "First, I need to recommend a movie. Since I don't have a specific context or preference from you, I'll choose a popular and highly-regarded film: **Parasite (2019)**.\n",
      "\n",
      "\n",
      "\n",
      "## Step 2: Summarize the Movie in 3 Sentences\n",
      "Now, I'll summarize the movie \"Parasite\" in three sentences, changing the lines for clarity:\n",
      "\n",
      "The Kims, a poor family living in a cramped semi-basement apartment in Seoul, struggle to make ends meet. \n",
      "One day, the family's fortunes change when the son, Ki-woo, lands a tutoring job with a wealthy family, the Parks, posing as a university student. \n",
      "As the Kims infiltrate the Parks' lives, pretending to be unrelated, highly qualified individuals, they become embroiled in a complex class struggle that leads to unexpected and tragic consequences.\n",
      "\n",
      "\n",
      "\n",
      "## Step 3: Provide the Requested Information\n",
      "- **Movie Title:** Parasite (2019)\n",
      "- **Summary in 3 Sentences (with line change):**\n",
      "\n",
      "  The Kims, a poor family living in a cramped semi-basement apartment in Seoul, struggle to make ends meet.\n",
      "\n",
      "  One day, the family's fortunes change when the son, Ki-woo, lands a tutoring job with a wealthy family, the Parks, posing as a university student.\n",
      "\n",
      "  As the Kims infiltrate the Parks' lives, pretending to be unrelated, highly qualified individuals, they become embroiled in a complex class struggle that leads to unexpected and tragic consequences.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import re\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 줄거리를 3문장으로 요약해 주세요.\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "movie_response = chain1.invoke({\"genre\": \"action\"})  # 영화 제목 얻기\n",
    "print(\" 추천된 영화 (원본 응답):\", movie_response)\n",
    "\n",
    "#  영화 제목만 추출 (첫 번째 큰따옴표 안의 문자열 찾기)\n",
    "match = re.search(r'\"(.*?)\"', movie_response)\n",
    "if match:\n",
    "    movie_title = match.group(1)\n",
    "else:\n",
    "    movie_title = movie_response.split(\" \")[0]  # 대안으로 첫 번째 단어 사용\n",
    "\n",
    "print(\" 추출된 영화 제목:\", movie_title)\n",
    "\n",
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = prompt2 | llm | StrOutputParser()\n",
    "\n",
    "# 실행: chain1의 출력(영화 제목)을 chain2에 명확히 전달\n",
    "response = chain2.invoke({\"movie\": movie_title})\n",
    "print(\"\\n 영화 줄거리 요약:\\n\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da31790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "langchain-app-qc8Qb1Xk-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
