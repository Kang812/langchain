{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic 생존 예측 데이터 분석\n",
    "## LangChain 에이전트를 활용한 포괄적 데이터 탐색\n",
    "\n",
    "이 노트북은 LangChain의 pandas 데이터프레임 에이전트를 사용하여 Titanic 데이터를 분석하고 생존 예측 모델을 구축합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "필요한 라이브러리 설치 확인 중...\n",
      "라이브러리 설치가 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "# !pip install langchain langchain-experimental langchain-openai pandas matplotlib seaborn numpy scikit-learn python-dotenv\n",
    "\n",
    "print(\"필요한 라이브러리 설치 확인 중...\")\n",
    "print(\"라이브러리 설치가 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "환경 설정 시작...\n",
      "OpenAI API 키가 성공적으로 로드되었습니다.\n",
      "환경 설정이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "print(\"환경 설정 시작...\")\n",
    "\n",
    "# 환경 변수에서 API 키 가져오기\n",
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 경고 메시지 숨기기\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "load_dotenv('../.env')\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"OPENAI_API_KEY가 설정되지 않았습니다. .env 파일을 확인해주세요.\")\n",
    "else:\n",
    "    print(\"OpenAI API 키가 성공적으로 로드되었습니다.\")\n",
    "\n",
    "print(\"환경 설정이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라이브러리 로드 중...\n",
      "라이브러리 로드가 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "print(\"라이브러리 로드 중...\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# 한글 폰트 설정\n",
    "plt.rcParams['font.family'] = ['나눔고딕', 'NanumGothic', 'Malgun Gothic']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# Seaborn 스타일 설정\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# pandas 옵션 설정\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"라이브러리 로드가 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로드 시작...\n",
      "Titanic 데이터 파일을 찾을 수 없습니다.\n",
      "현재 디렉토리에 train.csv와 test.csv 파일을 배치해주세요.\n",
      "샘플 Titanic 데이터를 생성합니다...\n",
      "샘플 데이터 생성이 완료되었습니다.\n",
      "\n",
      "=== 데이터 기본 정보 ===\n",
      "훈련 데이터: 891행 12열\n",
      "테스트 데이터: 418행 11열\n",
      "타겟 변수: Survived (생존 여부)\n"
     ]
    }
   ],
   "source": [
    "print(\"데이터 로드 시작...\")\n",
    "\n",
    "# 데이터 로드\n",
    "try:\n",
    "    train = pd.read_csv('./data/titanic/train.csv')\n",
    "    test = pd.read_csv('./data/titanic/test.csv')\n",
    "    \n",
    "    print(f\"훈련 데이터 로드 완료: {train.shape}\")\n",
    "    print(f\"테스트 데이터 로드 완료: {test.shape}\")\n",
    "    print(\"데이터 로드가 성공적으로 완료되었습니다.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Titanic 데이터 파일을 찾을 수 없습니다.\")\n",
    "    print(\"현재 디렉토리에 train.csv와 test.csv 파일을 배치해주세요.\")\n",
    "    \n",
    "    # 샘플 Titanic 데이터 생성\n",
    "    print(\"샘플 Titanic 데이터를 생성합니다...\")\n",
    "    np.random.seed(42)\n",
    "    n_samples = 891\n",
    "    \n",
    "    train = pd.DataFrame({\n",
    "        'PassengerId': range(1, n_samples + 1),\n",
    "        'Survived': np.random.choice([0, 1], n_samples, p=[0.62, 0.38]),\n",
    "        'Pclass': np.random.choice([1, 2, 3], n_samples, p=[0.24, 0.21, 0.55]),\n",
    "        'Name': [f'Name_{i}' for i in range(1, n_samples + 1)],\n",
    "        'Sex': np.random.choice(['male', 'female'], n_samples, p=[0.65, 0.35]),\n",
    "        'Age': np.random.normal(29.7, 14.5, n_samples),\n",
    "        'SibSp': np.random.choice([0, 1, 2, 3, 4, 5], n_samples, p=[0.68, 0.23, 0.06, 0.02, 0.01, 0.00]),\n",
    "        'Parch': np.random.choice([0, 1, 2, 3, 4, 5, 6], n_samples, p=[0.76, 0.13, 0.08, 0.02, 0.01, 0.00, 0.00]),\n",
    "        'Ticket': [f'Ticket_{i}' for i in range(1, n_samples + 1)],\n",
    "        'Fare': np.random.lognormal(3, 1, n_samples),\n",
    "        'Cabin': np.random.choice(['A1', 'B2', 'C3', None], n_samples, p=[0.1, 0.1, 0.1, 0.7]),\n",
    "        'Embarked': np.random.choice(['C', 'Q', 'S'], n_samples, p=[0.19, 0.09, 0.72])\n",
    "    })\n",
    "    \n",
    "    # 나이 결측값 추가 (약 20%)\n",
    "    train.loc[train.sample(frac=0.2).index, 'Age'] = np.nan\n",
    "    \n",
    "    test = train.drop(['Survived'], axis=1).head(418).copy()\n",
    "    test['PassengerId'] = range(892, 892 + 418)\n",
    "    \n",
    "    print(\"샘플 데이터 생성이 완료되었습니다.\")\n",
    "\n",
    "print(\"\\n=== 데이터 기본 정보 ===\")\n",
    "print(f\"훈련 데이터: {train.shape[0]}행 {train.shape[1]}열\")\n",
    "print(f\"테스트 데이터: {test.shape[0]}행 {test.shape[1]}열\")\n",
    "print(f\"타겟 변수: {'Survived (생존 여부)' if 'Survived' in train.columns else '없음'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 구조 분석 시작...\n",
      "=== 훈련 데이터 기본 정보 ===\n",
      "데이터 크기: (891, 12)\n",
      "결측값 총 개수: 793\n",
      "중복된 행: 0\n",
      "\n",
      "=== 테스트 데이터 기본 정보 ===\n",
      "데이터 크기: (418, 11)\n",
      "결측값 총 개수: 366\n",
      "중복된 행: 0\n",
      "\n",
      "=== 컬럼 비교 ===\n",
      "공통 컬럼: 11개\n",
      "훈련 데이터에만 있는 컬럼: {'Survived'}\n",
      "테스트 데이터에만 있는 컬럼: set()\n",
      "\n",
      "전체 생존율: 37.4%\n",
      "생존자: 333명\n",
      "사망자: 558명\n",
      "\n",
      "데이터 구조 분석이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "print(\"데이터 구조 분석 시작...\")\n",
    "\n",
    "# 기본 데이터 정보 확인\n",
    "print(\"=== 훈련 데이터 기본 정보 ===\")\n",
    "print(f\"데이터 크기: {train.shape}\")\n",
    "print(f\"결측값 총 개수: {train.isnull().sum().sum()}\")\n",
    "print(f\"중복된 행: {train.duplicated().sum()}\")\n",
    "\n",
    "print(\"\\n=== 테스트 데이터 기본 정보 ===\")\n",
    "print(f\"데이터 크기: {test.shape}\")\n",
    "print(f\"결측값 총 개수: {test.isnull().sum().sum()}\")\n",
    "print(f\"중복된 행: {test.duplicated().sum()}\")\n",
    "\n",
    "# 공통 컬럼과 차이점 확인\n",
    "train_cols = set(train.columns)\n",
    "test_cols = set(test.columns)\n",
    "common_cols = train_cols.intersection(test_cols)\n",
    "train_only = train_cols - test_cols\n",
    "test_only = test_cols - train_cols\n",
    "\n",
    "print(f\"\\n=== 컬럼 비교 ===\")\n",
    "print(f\"공통 컬럼: {len(common_cols)}개\")\n",
    "print(f\"훈련 데이터에만 있는 컬럼: {train_only}\")\n",
    "print(f\"테스트 데이터에만 있는 컬럼: {test_only}\")\n",
    "\n",
    "# 생존율 기본 정보\n",
    "if 'Survived' in train.columns:\n",
    "    survival_rate = train['Survived'].mean()\n",
    "    print(f\"\\n전체 생존율: {survival_rate:.1%}\")\n",
    "    print(f\"생존자: {train['Survived'].sum()}명\")\n",
    "    print(f\"사망자: {(train['Survived'] == 0).sum()}명\")\n",
    "\n",
    "print(\"\\n데이터 구조 분석이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 전처리 함수 정의 중...\n",
      "\n",
      "=== 훈련 데이터 결측치 행 분석 ===\n",
      "전체 행 수: 891\n",
      "완전한 행 (결측치 없음): 221 (24.8%)\n",
      "결측치가 있는 행: 670 (75.2%)\n",
      "모든 값이 결측치인 행: 0\n",
      "\n",
      "행별 결측치 개수 통계:\n",
      "평균: 0.89\n",
      "최대: 2\n",
      "표준편차: 0.61\n",
      "\n",
      "결측치가 가장 많은 5개 행:\n",
      "  행 1: 2개 결측치\n",
      "  행 3: 2개 결측치\n",
      "  행 16: 2개 결측치\n",
      "  행 22: 2개 결측치\n",
      "  행 35: 2개 결측치\n",
      "\n",
      "=== 테스트 데이터 결측치 행 분석 ===\n",
      "전체 행 수: 418\n",
      "완전한 행 (결측치 없음): 103 (24.6%)\n",
      "결측치가 있는 행: 315 (75.4%)\n",
      "모든 값이 결측치인 행: 0\n",
      "\n",
      "행별 결측치 개수 통계:\n",
      "평균: 0.88\n",
      "최대: 2\n",
      "표준편차: 0.59\n",
      "\n",
      "결측치가 가장 많은 5개 행:\n",
      "  행 1: 2개 결측치\n",
      "  행 3: 2개 결측치\n",
      "  행 16: 2개 결측치\n",
      "  행 22: 2개 결측치\n",
      "  행 35: 2개 결측치\n",
      "\n",
      "데이터 전처리 실행...\n",
      "훈련 데이터 전처리 시작...\n",
      "  Age 결측값 178개를 중앙값 28.6로 대체\n",
      "  Cabin 결측값 615개를 'Unknown'으로 대체\n",
      "  파생 변수 생성 완료 (FamilySize, IsAlone, AgeGroup, FareGroup)\n",
      "테스트 데이터 전처리 시작...\n",
      "  Age 결측값 80개를 중앙값 29.3로 대체\n",
      "  Cabin 결측값 286개를 'Unknown'으로 대체\n",
      "  파생 변수 생성 완료 (FamilySize, IsAlone, AgeGroup, FareGroup)\n",
      "\n",
      "데이터 전처리가 완료되었습니다.\n",
      "훈련 데이터 결측값: 13\n",
      "테스트 데이터 결측값: 7\n"
     ]
    }
   ],
   "source": [
    "print(\"데이터 전처리 함수 정의 중...\")\n",
    "\n",
    "def analyze_missing_rows(df, dataset_name=\"데이터\"):\n",
    "    \"\"\"결측치 행 분석 함수\"\"\"\n",
    "    print(f\"\\n=== {dataset_name} 결측치 행 분석 ===\")\n",
    "    \n",
    "    # 기본 정보\n",
    "    total_rows = len(df)\n",
    "    rows_with_missing = df.isnull().any(axis=1).sum()\n",
    "    rows_all_missing = df.isnull().all(axis=1).sum()\n",
    "    complete_rows = total_rows - rows_with_missing\n",
    "    \n",
    "    print(f\"전체 행 수: {total_rows:,}\")\n",
    "    print(f\"완전한 행 (결측치 없음): {complete_rows:,} ({complete_rows/total_rows*100:.1f}%)\")\n",
    "    print(f\"결측치가 있는 행: {rows_with_missing:,} ({rows_with_missing/total_rows*100:.1f}%)\")\n",
    "    print(f\"모든 값이 결측치인 행: {rows_all_missing:,}\")\n",
    "    \n",
    "    # 결측치 개수별 분포\n",
    "    missing_per_row = df.isnull().sum(axis=1)\n",
    "    if rows_with_missing > 0:\n",
    "        print(f\"\\n행별 결측치 개수 통계:\")\n",
    "        print(f\"평균: {missing_per_row.mean():.2f}\")\n",
    "        print(f\"최대: {missing_per_row.max()}\")\n",
    "        print(f\"표준편차: {missing_per_row.std():.2f}\")\n",
    "        \n",
    "        # 결측치가 많은 행들\n",
    "        worst_rows = missing_per_row.nlargest(5)\n",
    "        print(f\"\\n결측치가 가장 많은 5개 행:\")\n",
    "        for idx, count in worst_rows.items():\n",
    "            print(f\"  행 {idx}: {count}개 결측치\")\n",
    "    \n",
    "    return {\n",
    "        'total_rows': total_rows,\n",
    "        'complete_rows': complete_rows,\n",
    "        'rows_with_missing': rows_with_missing,\n",
    "        'rows_all_missing': rows_all_missing\n",
    "    }\n",
    "\n",
    "def preprocess_titanic_data(df, is_train=True):\n",
    "    \"\"\"Titanic 데이터 전처리 함수\"\"\"\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    print(f\"{'훈련' if is_train else '테스트'} 데이터 전처리 시작...\")\n",
    "    \n",
    "    # 나이 결측값을 중앙값으로 채우기\n",
    "    if df_processed['Age'].isnull().sum() > 0:\n",
    "        age_median = df_processed['Age'].median()\n",
    "        df_processed['Age'].fillna(age_median, inplace=True)\n",
    "        print(f\"  Age 결측값 {df['Age'].isnull().sum()}개를 중앙값 {age_median:.1f}로 대체\")\n",
    "    \n",
    "    # Embarked 결측값을 최빈값으로 채우기\n",
    "    if df_processed['Embarked'].isnull().sum() > 0:\n",
    "        embarked_mode = df_processed['Embarked'].mode()[0]\n",
    "        df_processed['Embarked'].fillna(embarked_mode, inplace=True)\n",
    "        print(f\"  Embarked 결측값 {df['Embarked'].isnull().sum()}개를 최빈값 '{embarked_mode}'로 대체\")\n",
    "    \n",
    "    # Fare 결측값을 중앙값으로 채우기\n",
    "    if df_processed['Fare'].isnull().sum() > 0:\n",
    "        fare_median = df_processed['Fare'].median()\n",
    "        df_processed['Fare'].fillna(fare_median, inplace=True)\n",
    "        print(f\"  Fare 결측값 {df['Fare'].isnull().sum()}개를 중앙값 {fare_median:.2f}로 대체\")\n",
    "    \n",
    "    # Cabin 결측값을 'Unknown'으로 채우기\n",
    "    if df_processed['Cabin'].isnull().sum() > 0:\n",
    "        cabin_missing = df_processed['Cabin'].isnull().sum()\n",
    "        df_processed['Cabin'].fillna('Unknown', inplace=True)\n",
    "        print(f\"  Cabin 결측값 {cabin_missing}개를 'Unknown'으로 대체\")\n",
    "    \n",
    "    # 파생 변수 생성\n",
    "    df_processed['FamilySize'] = df_processed['SibSp'] + df_processed['Parch'] + 1\n",
    "    df_processed['IsAlone'] = (df_processed['FamilySize'] == 1).astype(int)\n",
    "    \n",
    "    # 나이 그룹 생성\n",
    "    df_processed['AgeGroup'] = pd.cut(df_processed['Age'], \n",
    "                                    bins=[0, 18, 30, 50, 100], \n",
    "                                    labels=['Child', 'Young', 'Adult', 'Senior'])\n",
    "    \n",
    "    # 요금 그룹 생성\n",
    "    df_processed['FareGroup'] = pd.qcut(df_processed['Fare'], \n",
    "                                      q=4, \n",
    "                                      labels=['Low', 'Medium', 'High', 'VeryHigh'])\n",
    "    \n",
    "    print(f\"  파생 변수 생성 완료 (FamilySize, IsAlone, AgeGroup, FareGroup)\")\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "# 결측치 행 분석 실행\n",
    "train_missing_info = analyze_missing_rows(train, \"훈련 데이터\")\n",
    "test_missing_info = analyze_missing_rows(test, \"테스트 데이터\")\n",
    "\n",
    "# 데이터 전처리 적용\n",
    "print(\"\\n데이터 전처리 실행...\")\n",
    "train_processed = preprocess_titanic_data(train, is_train=True)\n",
    "test_processed = preprocess_titanic_data(test, is_train=False)\n",
    "\n",
    "print(f\"\\n데이터 전처리가 완료되었습니다.\")\n",
    "print(f\"훈련 데이터 결측값: {train_processed.isnull().sum().sum()}\")\n",
    "print(f\"테스트 데이터 결측값: {test_processed.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain 에이전트 설정 시작...\n",
      "LangChain 에이전트가 성공적으로 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "print(\"LangChain 에이전트 설정 시작...\")\n",
    "\n",
    "# LangChain 에이전트 설정\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM 초기화\n",
    "#llm = ChatOpenAI(\n",
    "#    model='gpt-3.5-turbo-0125', \n",
    "#    #model='gpt-4o-mini',\n",
    "#    temperature=0,\n",
    "#    api_key=OPENAI_API_KEY\n",
    "#)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 훈련 데이터용 에이전트 생성\n",
    "train_agent = create_pandas_dataframe_agent(\n",
    "    llm,\n",
    "    train_processed,\n",
    "    agent_type=\"openai-tools\",\n",
    "    #agent_type=\"tool-calling\",\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=False,\n",
    "    allow_dangerous_code=True,\n",
    "    prefix=\"\"\"당신은 Titanic 생존 예측 데이터셋을 분석하는 전문가입니다. \n",
    "    데이터프레임의 이름은 'df'입니다. 한국어로 답변해주세요.\n",
    "    시각화를 요청받으면 matplotlib/seaborn을 사용하여 한국어 제목과 라벨로 깔끔하고 이해하기 쉬운 그래프를 만들어주세요.\n",
    "    Titanic 데이터의 특성을 고려하여 생존율, 승객 등급, 성별, 나이 등의 관점에서 분석해주세요.\"\"\"\n",
    ")\n",
    "\n",
    "print(\"LangChain 에이전트가 성공적으로 생성되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본 데이터 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기본 통계 정보 분석 시작...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "APIError",
     "evalue": "Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAPIError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m기본 통계 정보 분석 시작...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# 기본 통계 정보 확인\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m response = \u001b[43mtrain_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\"\"\u001b[39;49m\n\u001b[32m      5\u001b[39m \u001b[33;43mTitanic 데이터의 기본 통계 정보를 분석해주세요:\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[33;43m1. 전체 승객 수와 생존자 수\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[33;43m2. 생존율 (백분율로)\u001b[39;49m\n\u001b[32m      8\u001b[39m \u001b[33;43m3. 주요 수치형 변수들의 기본 통계량 (Age, Fare, FamilySize)\u001b[39;49m\n\u001b[32m      9\u001b[39m \u001b[33;43m4. 범주형 변수들의 분포 (Pclass, Sex, Embarked)\u001b[39;49m\n\u001b[32m     10\u001b[39m \n\u001b[32m     11\u001b[39m \u001b[33;43m한국어로 자세히 설명해주세요.\u001b[39;49m\n\u001b[32m     12\u001b[39m \u001b[33;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(response[\u001b[33m'\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m기본 통계 정보 분석이 완료되었습니다.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kosta\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-app-qc8Qb1Xk-py3.12\\Lib\\site-packages\\langchain\\chains\\base.py:167\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    166\u001b[39m     run_manager.on_chain_error(e)\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    168\u001b[39m run_manager.on_chain_end(outputs)\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kosta\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-app-qc8Qb1Xk-py3.12\\Lib\\site-packages\\langchain\\chains\\base.py:157\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    155\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    156\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    159\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    160\u001b[39m     )\n\u001b[32m    162\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    163\u001b[39m         inputs, outputs, return_only_outputs\n\u001b[32m    164\u001b[39m     )\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kosta\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-app-qc8Qb1Xk-py3.12\\Lib\\site-packages\\langchain\\agents\\agent.py:1620\u001b[39m, in \u001b[36mAgentExecutor._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m   1618\u001b[39m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[32m   1619\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_continue(iterations, time_elapsed):\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m     next_step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1621\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1622\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1623\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1624\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1627\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[32m   1628\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._return(\n\u001b[32m   1629\u001b[39m             next_step_output, intermediate_steps, run_manager=run_manager\n\u001b[32m   1630\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kosta\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-app-qc8Qb1Xk-py3.12\\Lib\\site-packages\\langchain\\agents\\agent.py:1328\u001b[39m, in \u001b[36mAgentExecutor._take_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1317\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_take_next_step\u001b[39m(\n\u001b[32m   1318\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1319\u001b[39m     name_to_tool_map: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1323\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1324\u001b[39m ) -> Union[AgentFinish, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[32m   1325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._consume_next_step(\n\u001b[32m   1326\u001b[39m         \u001b[43m[\u001b[49m\n\u001b[32m   1327\u001b[39m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m1328\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   1336\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kosta\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-app-qc8Qb1Xk-py3.12\\Lib\\site-packages\\langchain\\agents\\agent.py:1354\u001b[39m, in \u001b[36mAgentExecutor._iter_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1351\u001b[39m     intermediate_steps = \u001b[38;5;28mself\u001b[39m._prepare_intermediate_steps(intermediate_steps)\n\u001b[32m   1353\u001b[39m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1354\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_action_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1355\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1356\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1357\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1358\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1359\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1360\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.handle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kosta\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-app-qc8Qb1Xk-py3.12\\Lib\\site-packages\\langchain\\agents\\agent.py:577\u001b[39m, in \u001b[36mRunnableMultiActionAgent.plan\u001b[39m\u001b[34m(self, intermediate_steps, callbacks, **kwargs)\u001b[39m\n\u001b[32m    569\u001b[39m final_output: Any = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    570\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream_runnable:\n\u001b[32m    571\u001b[39m     \u001b[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[32m    572\u001b[39m     \u001b[38;5;66;03m# streaming\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    575\u001b[39m     \u001b[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[32m    576\u001b[39m     \u001b[38;5;66;03m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m577\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrunnable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kosta\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-app-qc8Qb1Xk-py3.12\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3438\u001b[39m, in \u001b[36mRunnableSequence.stream\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3431\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   3432\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstream\u001b[39m(\n\u001b[32m   3433\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3436\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   3437\u001b[39m ) -> Iterator[Output]:\n\u001b[32m-> \u001b[39m\u001b[32m3438\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kosta\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-app-qc8Qb1Xk-py3.12\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3424\u001b[39m, in \u001b[36mRunnableSequence.transform\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3417\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   3418\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransform\u001b[39m(\n\u001b[32m   3419\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3422\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   3423\u001b[39m ) -> Iterator[Output]:\n\u001b[32m-> \u001b[39m\u001b[32m3424\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transform_stream_with_config(\n\u001b[32m   3425\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   3426\u001b[39m         \u001b[38;5;28mself\u001b[39m._transform,\n\u001b[32m   3427\u001b[39m         patch_config(config, run_name=(config \u001b[38;5;129;01mor\u001b[39;00m {}).get(\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.name),\n\u001b[32m   3428\u001b[39m         **kwargs,\n\u001b[32m   3429\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kosta\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-app-qc8Qb1Xk-py3.12\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2215\u001b[39m, in \u001b[36mRunnable._transform_stream_with_config\u001b[39m\u001b[34m(self, inputs, transformer, config, run_type, **kwargs)\u001b[39m\n\u001b[32m   2213\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2214\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2215\u001b[39m         chunk: Output = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2216\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[32m   2217\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kosta\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-app-qc8Qb1Xk-py3.12\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3386\u001b[39m, in \u001b[36mRunnableSequence._transform\u001b[39m\u001b[34m(self, inputs, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m   3383\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3384\u001b[39m         final_pipeline = step.transform(final_pipeline, config)\n\u001b[32m-> \u001b[39m\u001b[32m3386\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m final_pipeline\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kosta\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-app-qc8Qb1Xk-py3.12\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1429\u001b[39m, in \u001b[36mRunnable.transform\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   1426\u001b[39m final: Input\n\u001b[32m   1427\u001b[39m got_first_val = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1429\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   1430\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# The default implementation of transform is to buffer input and\u001b[39;49;00m\n\u001b[32m   1431\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# then call stream.\u001b[39;49;00m\n\u001b[32m   1432\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# It'll attempt to gather all input into a single chunk using\u001b[39;49;00m\n\u001b[32m   1433\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# the `+` operator.\u001b[39;49;00m\n\u001b[32m   1434\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If the input is not addable, then we'll assume that we can\u001b[39;49;00m\n\u001b[32m   1435\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# only operate on the last chunk,\u001b[39;49;00m\n\u001b[32m   1436\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# and we'll iterate until we get to the last chunk.\u001b[39;49;00m\n\u001b[32m   1437\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgot_first_val\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1438\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kosta\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-app-qc8Qb1Xk-py3.12\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5647\u001b[39m, in \u001b[36mRunnableBindingBase.transform\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5640\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5641\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransform\u001b[39m(\n\u001b[32m   5642\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5645\u001b[39m     **kwargs: Any,\n\u001b[32m   5646\u001b[39m ) -> Iterator[Output]:\n\u001b[32m-> \u001b[39m\u001b[32m5647\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bound.transform(\n\u001b[32m   5648\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   5649\u001b[39m         \u001b[38;5;28mself\u001b[39m._merge_configs(config),\n\u001b[32m   5650\u001b[39m         **{**\u001b[38;5;28mself\u001b[39m.kwargs, **kwargs},\n\u001b[32m   5651\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kosta\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-app-qc8Qb1Xk-py3.12\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1447\u001b[39m, in \u001b[36mRunnable.transform\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   1444\u001b[39m             final = ichunk\n\u001b[32m   1446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[32m-> \u001b[39m\u001b[32m1447\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream(final, config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kosta\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-app-qc8Qb1Xk-py3.12\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:499\u001b[39m, in \u001b[36mBaseChatModel.stream\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    497\u001b[39m input_messages = _normalize_messages(messages)\n\u001b[32m    498\u001b[39m run_id = \u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m.join((_LC_ID_PREFIX, \u001b[38;5;28mstr\u001b[39m(run_manager.run_id)))\n\u001b[32m--> \u001b[39m\u001b[32m499\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_id\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kosta\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-app-qc8Qb1Xk-py3.12\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1048\u001b[39m, in \u001b[36mBaseChatOpenAI._stream\u001b[39m\u001b[34m(self, messages, stop, run_manager, stream_usage, **kwargs)\u001b[39m\n\u001b[32m   1046\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context_manager \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[32m   1047\u001b[39m     is_first_chunk = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1048\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1049\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kosta\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-app-qc8Qb1Xk-py3.12\\Lib\\site-packages\\openai\\_streaming.py:46\u001b[39m, in \u001b[36mStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[_T]:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kosta\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-app-qc8Qb1Xk-py3.12\\Lib\\site-packages\\openai\\_streaming.py:91\u001b[39m, in \u001b[36mStream.__stream__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     88\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m message \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m     89\u001b[39m                 message = \u001b[33m\"\u001b[39m\u001b[33mAn error occurred during streaming\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m APIError(\n\u001b[32m     92\u001b[39m                 message=message,\n\u001b[32m     93\u001b[39m                 request=\u001b[38;5;28mself\u001b[39m.response.request,\n\u001b[32m     94\u001b[39m                 body=data[\u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     95\u001b[39m             )\n\u001b[32m     97\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m process_data(data={\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m: data, \u001b[33m\"\u001b[39m\u001b[33mevent\u001b[39m\u001b[33m\"\u001b[39m: sse.event}, cast_to=cast_to, response=response)\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# Ensure the entire stream is consumed\u001b[39;00m\n",
      "\u001b[31mAPIError\u001b[39m: Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details."
     ]
    }
   ],
   "source": [
    "print(\"기본 통계 정보 분석 시작...\")\n",
    "\n",
    "# 기본 통계 정보 확인\n",
    "response = train_agent.invoke(\"\"\"\n",
    "Titanic 데이터의 기본 통계 정보를 분석해주세요:\n",
    "1. 전체 승객 수와 생존자 수\n",
    "2. 생존율 (백분율로)\n",
    "3. 주요 수치형 변수들의 기본 통계량 (Age, Fare, FamilySize)\n",
    "4. 범주형 변수들의 분포 (Pclass, Sex, Embarked)\n",
    "\n",
    "한국어로 자세히 설명해주세요.\n",
    "\"\"\")\n",
    "print(response['output'])\n",
    "print(\"\\n기본 통계 정보 분석이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"생존율 분포 시각화 시작...\")\n",
    "\n",
    "# 생존율 시각화\n",
    "response = train_agent.invoke(\"\"\"\n",
    "먼저 한글 폰트를 설정하세요:\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'  # Windows\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "                              \n",
    "생존 여부(Survived)에 대한 다음 시각화를 생성해주세요:\n",
    "1. 생존/사망 비율을 보여주는 원형 차트 (한국어 라벨)\n",
    "2. 생존/사망 개수를 보여주는 막대 차트 (한국어 제목과 라벨)\n",
    "\n",
    "그래프는 한국어 제목과 라벨을 사용하고,\n",
    "subplot을 사용하여 한 화면에 두 차트를 배치하고, \n",
    "각 차트에 정확한 숫자와 백분율을 표시해주세요.\n",
    "\"\"\")\n",
    "print(response['output'])\n",
    "print(\"\\n생존율 분포 시각화가 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 상관관계 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"생존율과 변수들의 상관관계 분석 시작...\")\n",
    "\n",
    "# 생존율과 상관관계가 높은 변수들 찾기\n",
    "response = train_agent.invoke(\"\"\"\n",
    "생존 여부(Survived)와 다른 수치형 변수들 간의 상관관계를 분석해주세요:\n",
    "1. 상관계수 계산 (Age, Fare, Pclass, SibSp, Parch, FamilySize, IsAlone)\n",
    "2. 상관계수를 막대그래프로 시각화 (절댓값 기준으로 정렬)\n",
    "3. 가장 상관관계가 높은 상위 5개 변수 설명\n",
    "4. 히트맵으로 전체 상관관계 매트릭스 표시\n",
    "\n",
    "모든 그래프에 한국어 제목과 라벨을 사용해주세요.\n",
    "\"\"\")\n",
    "print(response['output'])\n",
    "print(\"\\n상관관계 분석이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 범주형 변수 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"범주형 변수 분석 시작...\")\n",
    "\n",
    "# 성별에 따른 생존율\n",
    "response = train_agent.invoke(\"\"\"\n",
    "먼저 한글 폰트를 설정하세요:\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'  # Windows\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "                                                            \n",
    "성별(Sex)에 따른 생존율을 분석하고 시각화해주세요:\n",
    "1. 성별(Sex) 생존자 수와 사망자 수를 스택형 막대그래프로 표시\n",
    "2. 성별(Sex) 생존율을 백분율로 계산하여 표시\n",
    "3. 성별(Sex)이 생존에 미치는 영향에 대한 분석\n",
    "\n",
    "한국어 제목과 라벨을 사용하고, 정확한 숫자와 백분율을 그래프에 표시해주세요.\n",
    "\"\"\")\n",
    "print(response['output'])\n",
    "print(\"\\n성별 분석이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"승객 등급별 생존율 분석 시작...\")\n",
    "\n",
    "# 승객 등급별 생존율\n",
    "response = train_agent.invoke(\"\"\"\n",
    "승객 등급(Pclass)에 따른 생존율을 분석해주세요:\n",
    "1. 등급별 승객 수 분포 (막대그래프)\n",
    "2. 등급별 생존율 비교 (막대그래프)\n",
    "3. 등급별 평균 요금(Fare) 비교 (박스플롯)\n",
    "\n",
    "subplot을 사용하여 세 개의 그래프를 한 화면에 배치하고,\n",
    "막대별로 색상을 다르게 사용해 주세요.                              \n",
    "모든 그래프에 한국어 제목과 라벨을 사용해주세요.\n",
    "\"\"\")\n",
    "print(response['output'])\n",
    "print(\"\\n승객 등급 분석이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예측 모델 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"예측 모델 구축 시작...\")\n",
    "\n",
    "def build_titanic_model():\n",
    "    \"\"\"Titanic 생존 예측 모델 구축\"\"\"\n",
    "    \n",
    "    print(\"모델 구축 준비 중...\")\n",
    "    \n",
    "    # 특성 선택 (수치형 변수만 선택)\n",
    "    if 'Survived' in train_processed.columns:\n",
    "        # 범주형 변수를 수치형으로 변환\n",
    "        train_model = train_processed.copy()\n",
    "        \n",
    "        # 성별을 수치형으로 변환\n",
    "        train_model['Sex_encoded'] = (train_model['Sex'] == 'male').astype(int)\n",
    "        \n",
    "        # 승선 항구를 수치형으로 변환\n",
    "        embarked_dummies = pd.get_dummies(train_model['Embarked'], prefix='Embarked')\n",
    "        train_model = pd.concat([train_model, embarked_dummies], axis=1)\n",
    "        \n",
    "        # 연령 그룹을 수치형으로 변환\n",
    "        train_model['AgeGroup_encoded'] = train_model['AgeGroup'].cat.codes\n",
    "        \n",
    "        # 요금 그룹을 수치형으로 변환  \n",
    "        train_model['FareGroup_encoded'] = train_model['FareGroup'].cat.codes\n",
    "        \n",
    "        # 모델링에 사용할 특성 선택\n",
    "        feature_cols = ['Pclass', 'Sex_encoded', 'Age', 'SibSp', 'Parch', 'Fare', \n",
    "                       'FamilySize', 'IsAlone', 'AgeGroup_encoded', 'FareGroup_encoded']\n",
    "        \n",
    "        # 승선 항구 더미 변수 추가\n",
    "        embarked_cols = [col for col in train_model.columns if col.startswith('Embarked_')]\n",
    "        feature_cols.extend(embarked_cols)\n",
    "        \n",
    "        # 사용 가능한 특성만 선택\n",
    "        available_features = [col for col in feature_cols if col in train_model.columns]\n",
    "        \n",
    "        X = train_model[available_features]\n",
    "        y = train_model['Survived']\n",
    "        \n",
    "        print(f\"사용된 특성: {len(available_features)}개\")\n",
    "        print(f\"   - {', '.join(available_features)}\")\n",
    "        \n",
    "        # 훈련/검증 분할\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "        \n",
    "        print(f\"데이터 분할 완료:\")\n",
    "        print(f\"   - 훈련 데이터: {X_train.shape[0]}개\")\n",
    "        print(f\"   - 검증 데이터: {X_val.shape[0]}개\")\n",
    "        \n",
    "        # 여러 모델 훈련\n",
    "        models = {\n",
    "            'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10),\n",
    "            'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000)\n",
    "        }\n",
    "        \n",
    "        model_results = {}\n",
    "        \n",
    "        for model_name, model in models.items():\n",
    "            print(f\"\\n {model_name} 모델 훈련 중...\")\n",
    "            \n",
    "            # 모델 훈련\n",
    "            if model_name == 'LogisticRegression':\n",
    "                # 로지스틱 회귀를 위한 스케일링\n",
    "                scaler = StandardScaler()\n",
    "                X_train_scaled = scaler.fit_transform(X_train)\n",
    "                X_val_scaled = scaler.transform(X_val)\n",
    "                model.fit(X_train_scaled, y_train)\n",
    "                y_pred = model.predict(X_val_scaled)\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_val)\n",
    "            \n",
    "            # 성능 평가\n",
    "            accuracy = accuracy_score(y_val, y_pred)\n",
    "            \n",
    "            model_results[model_name] = {\n",
    "                'model': model,\n",
    "                'accuracy': accuracy,\n",
    "                'predictions': y_pred\n",
    "            }\n",
    "            \n",
    "            print(f\"{model_name} 정확도: {accuracy:.4f}\")\n",
    "        \n",
    "        # 최고 성능 모델 선택\n",
    "        best_model_name = max(model_results.keys(), key=lambda k: model_results[k]['accuracy'])\n",
    "        best_model = model_results[best_model_name]['model']\n",
    "        best_accuracy = model_results[best_model_name]['accuracy']\n",
    "        \n",
    "        print(f\"\\n 최고 성능 모델: {best_model_name} (정확도: {best_accuracy:.4f})\")\n",
    "        \n",
    "        # 특성 중요도 (RandomForest인 경우)\n",
    "        if best_model_name == 'RandomForest':\n",
    "            feature_importance = pd.DataFrame({\n",
    "                'feature': available_features,\n",
    "                'importance': best_model.feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            print(\"\\n특성 중요도 분석:\")\n",
    "            for idx, row in feature_importance.head(10).iterrows():\n",
    "                print(f\"   {row['feature']}: {row['importance']:.4f}\")\n",
    "            \n",
    "            # 특성 중요도 시각화\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            top_features = feature_importance.head(10)\n",
    "            plt.barh(top_features['feature'], top_features['importance'])\n",
    "            plt.title('상위 10개 특성 중요도', fontsize=14, fontweight='bold')\n",
    "            plt.xlabel('중요도')\n",
    "            plt.ylabel('특성')\n",
    "            plt.gca().invert_yaxis()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        # 혼동 행렬\n",
    "        cm = confusion_matrix(y_val, model_results[best_model_name]['predictions'])\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=['사망', '생존'], yticklabels=['사망', '생존'])\n",
    "        plt.title(f'{best_model_name} 혼동 행렬', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('예측값')\n",
    "        plt.ylabel('실제값')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # 분류 보고서\n",
    "        print(f\"\\n {best_model_name} 분류 보고서:\")\n",
    "        print(classification_report(y_val, model_results[best_model_name]['predictions'], \n",
    "                                  target_names=['사망', '생존']))\n",
    "        \n",
    "        return best_model, feature_importance if best_model_name == 'RandomForest' else None, model_results\n",
    "    \n",
    "    else:\n",
    "        print(\" Survived 컬럼이 없어서 모델을 구축할 수 없습니다.\")\n",
    "        return None, None, None\n",
    "\n",
    "# 모델 구축 실행\n",
    "model, feature_importance, model_results = build_titanic_model()\n",
    "print(\"\\n예측 모델 구축이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 종합 인사이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"종합 인사이트 생성 시작...\")\n",
    "\n",
    "# 최종 인사이트 요청\n",
    "response = train_agent.invoke(\"\"\"\n",
    "지금까지의 Titanic 데이터 분석을 바탕으로 종합적인 인사이트를 제공해주세요:\n",
    "\n",
    "1. **생존에 가장 큰 영향을 미치는 상위 5개 요인**\n",
    "   - 각 요인이 생존율에 미치는 구체적인 영향\n",
    "   - 수치적 근거와 함께 설명\n",
    "\n",
    "2. **주목할 만한 패턴이나 트렌드**\n",
    "   - 성별, 승객 등급, 연령, 가족 구성 등의 상호작용\n",
    "   - 예상과 다른 흥미로운 발견사항\n",
    "\n",
    "3. **실제 역사적 맥락에서의 해석**\n",
    "   - 1912년 사회적 배경과 분석 결과의 연관성\n",
    "   - 'Women and children first' 원칙의 데이터상 확인\n",
    "\n",
    "각 항목에 대해 구체적인 수치와 예시를 들어 한국어로 상세히 설명해주세요.\n",
    "\"\"\")\n",
    "print(response['output'])\n",
    "print(\"\\n 종합 인사이트 생성이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추가 분석 함수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"추가 분석 함수 정의 중...\")\n",
    "\n",
    "# 사용자 정의 분석 함수\n",
    "def custom_titanic_analysis(question):\n",
    "    \"\"\"사용자 정의 질문으로 Titanic 분석 수행\"\"\"\n",
    "    try:\n",
    "        print(f\" 분석 질문: {question}\")\n",
    "        response = train_agent.invoke(question)\n",
    "        return response['output']\n",
    "    except Exception as e:\n",
    "        return f\" 분석 중 오류가 발생했습니다: {str(e)}\"\n",
    "\n",
    "def survival_analysis_by_group(group_column):\n",
    "    \"\"\"특정 그룹별 생존율 분석\"\"\"\n",
    "    if group_column in train_processed.columns:\n",
    "        survival_by_group = train_processed.groupby(group_column)['Survived'].agg(['count', 'sum', 'mean'])\n",
    "        survival_by_group.columns = ['총 승객 수', '생존자 수', '생존율']\n",
    "        survival_by_group['생존율(%)'] = (survival_by_group['생존율'] * 100).round(1)\n",
    "        \n",
    "        print(f\"\\n {group_column}별 생존율 분석:\")\n",
    "        print(survival_by_group)\n",
    "        \n",
    "        # 시각화\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        survival_by_group['생존율(%)'].plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "        plt.title(f'{group_column}별 생존율', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel(group_column)\n",
    "        plt.ylabel('생존율 (%)')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 막대 위에 값 표시\n",
    "        for i, v in enumerate(survival_by_group['생존율(%)']):\n",
    "            plt.text(i, v + 1, f'{v}%', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return survival_by_group\n",
    "    else:\n",
    "        print(f\" '{group_column}' 컬럼을 찾을 수 없습니다.\")\n",
    "        return None\n",
    "\n",
    "# 분석 함수들 테스트\n",
    "print(\" 추가 분석 함수들이 준비되었습니다.\")\n",
    "print(\"\\n 사용 가능한 분석 함수들:\")\n",
    "print(\"1. custom_titanic_analysis('질문') - 자유로운 분석 질문\")\n",
    "print(\"2. survival_analysis_by_group('컬럼명') - 그룹별 생존율 분석\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 대화형 분석 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" 대화형 분석 예시 준비 중...\")\n",
    "\n",
    "print(\"=== 대화형 분석 예시 ===\")\n",
    "print(\"\\n 이제 자연어로 다양한 분석을 요청할 수 있습니다!\")\n",
    "print(\"\\n 분석 예시 질문들:\")\n",
    "\n",
    "example_questions = [\n",
    "    \"가장 생존율이 높은 승객 프로필은 무엇인가요?\",\n",
    "    \"나이와 성별을 동시에 고려했을 때 생존율 패턴은 어떻게 되나요?\",\n",
    "    \"1등급 승객 중에서도 사망한 사람들의 특징은 무엇인가요?\",\n",
    "    \"가족과 함께 탄 승객과 혼자 탄 승객의 생존율 차이의 원인은?\",\n",
    "    \"요금이 가장 비싼 상위 10% 승객들의 생존율은?\",\n",
    "    \"각 승선 항구별로 승객 특성과 생존율이 어떻게 다른가요?\",\n",
    "    \"어린이(18세 미만)와 노인(60세 이상)의 생존율 비교\",\n",
    "    \"객실 번호(Cabin)가 있는 승객과 없는 승객의 생존율 차이\"\n",
    "]\n",
    "\n",
    "for i, question in enumerate(example_questions, 1):\n",
    "    print(f\"{i}. {question}\")\n",
    "\n",
    "print(\"\\n 사용법:\")\n",
    "print(\"result = custom_titanic_analysis('원하는 질문')\")\n",
    "print(\"print(result)\")\n",
    "\n",
    "print(\"\\n 예시 실행:\")\n",
    "print(\"# 예: 1등급 여성 승객의 생존율 분석\")\n",
    "print(\"# result = custom_titanic_analysis('1등급 여성 승객들의 생존율과 특징을 분석해주세요')\")\n",
    "\n",
    "print(\"\\n 모든 분석이 완료되었습니다!\")\n",
    "print(\" Titanic 데이터 분석 노트북이 성공적으로 실행되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최종 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 요약 정보 출력\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TITANIC 데이터 분석 완료 요약\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if 'Survived' in train_processed.columns:\n",
    "    total_passengers = len(train_processed)\n",
    "    survivors = train_processed['Survived'].sum()\n",
    "    survival_rate = train_processed['Survived'].mean()\n",
    "    \n",
    "    print(f\" 총 승객 수: {total_passengers:,}명\")\n",
    "    print(f\" 생존자 수: {survivors:,}명\")\n",
    "    print(f\" 사망자 수: {total_passengers - survivors:,}명\")\n",
    "    print(f\" 전체 생존율: {survival_rate:.1%}\")\n",
    "\n",
    "print(f\"\\n 전처리 후 결측값:\")\n",
    "print(f\"   - 훈련 데이터: {train_processed.isnull().sum().sum()}개\")\n",
    "print(f\"   - 테스트 데이터: {test_processed.isnull().sum().sum()}개\")\n",
    "\n",
    "if 'model_results' in locals() and model_results:\n",
    "    best_model_name = max(model_results.keys(), key=lambda k: model_results[k]['accuracy'])\n",
    "    best_accuracy = model_results[best_model_name]['accuracy']\n",
    "    print(f\"\\n 최고 성능 모델: {best_model_name}\")\n",
    "    print(f\" 예측 정확도: {best_accuracy:.1%}\")\n",
    "\n",
    "print(f\"\\n 생성된 파생 변수:\")\n",
    "derived_vars = ['FamilySize', 'IsAlone', 'AgeGroup', 'FareGroup']\n",
    "for var in derived_vars:\n",
    "    if var in train_processed.columns:\n",
    "        print(f\"  {var}\")\n",
    "\n",
    "print(\"\\n 분석이 완료되었습니다. 추가 질문이 있으시면 custom_titanic_analysis() 함수를 사용해주세요!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-app-qc8Qb1Xk-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
